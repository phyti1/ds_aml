---
title: "aml"
subtitle: "Mini-Challenge 1"
author: "Pascal Berger und Raphael Strebel"
date: "18. Oktober 2022"
output:
  html_notebook:
    toc: true
    toc_depth: 4
    df_print: paged
    toc_float:
      collapsed: true
      smooth_scroll: true
    theme: united
    highlight: tango
    code_folding: hide
---
R-Version: **[Default] [64-bit] C:\\Program Files\\R\\R-4.1.0**

# Imports

```{r echo=FALSE, cache=FALSE, results=FALSE, comment=FALSE, warning=FALSE}
# clear environment
rm(list = ls())

# nötige Packete
packages <- c("tidyverse", "data.table", "tidymodels", "lubridate", "caret", "pROC", "randomForest", "rpart", "rpart.plot")

# Noch nicht installierte Pakete installieren
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# Laden der Packete
invisible(lapply(packages, library, character.only = TRUE))

# change options
options(dplyr.summarise.inform = FALSE)
```

In folgendem Junk werden alle Tabellen aus den CSV's eingelesen.
Doku Daten: https://sorry.vse.cz/~berka/challenge/PAST/index.html
(rechte Seite PKDD'99 Challenge > Data > Financial Data Description)


# Einlesen der Daten

Der Datensatz besteht aus acht verschiedenen Tabellen, welche teils durch Keys miteinander verknüpft sind.
```{r}
root_path <- "./xselling_banking_data-1/xselling_banking_data/"

accounts <- read.csv(paste0(root_path, "account.csv"), header = TRUE, sep = ";")
cards <- read.csv(paste0(root_path, "card.csv"), header = TRUE, sep = ";")
clients <- read.csv(paste0(root_path, "client.csv"), header = TRUE, sep = ";")
dispositions <- read.csv(paste0(root_path, "disp.csv"), header = TRUE, sep = ";")
districts <- read.csv(paste0(root_path, "district.csv"), sep = ";")
loans <- read.csv(paste0(root_path, "loan.csv"), header = TRUE, sep = ";")
orders <- read.csv(paste0(root_path, "order.csv"), header = TRUE, sep = ";")
transactions <- read.csv(paste0(root_path, "trans.csv"), header = TRUE, sep = ";")
```

# Cleaning

## Accounts
```{r}
sample_n(accounts, 5)
```
Die Account-Tabelle enthält vier Kolonnen: die Account-ID, die District-ID (welche auf die District-Tabelle verweist), die Frequenz, welche die Häufigkeit der Ausstellung der Abrechnungen als Kategorie besagt, und das Erstellungsdatum des Accounts. Die Frequenz kann eine von drei verschiedenen Werten annehmen.

```{r}
unique(accounts$frequency)
```

Nachfolgend sollen die Frequenz-Werte übersetzt und das Datum in ein richtiges Format transformiert werden. Ausserdem soll die Tabelle auf fehlende Werte überprüft werden.

```{r}
accounts$date <- as.Date(as.character(accounts$date), format= "%y%m%d")

accounts$frequency[accounts$frequency == "POPLATEK MESICNE"]   <- "monthly"
accounts$frequency[accounts$frequency == "POPLATEK TYDNE"]     <- "weekly"
accounts$frequency[accounts$frequency == "POPLATEK PO OBRATU"] <- "after_transaction"

sum(is.na(accounts))
```

Es gibt also keine fehlende Werte in diesem Dataframe.

## Cards

```{r}
sample_n(cards, 5)
```
Auch bei card muss das Datum umgewandelt werden, der zeitliche Teil wird ignoriert, da er immer 0 ist.

```{r}
cards$issued <- as.Date(as.character(cards$issued), format= "%y%m%d")

cards$type[cards$type == "gold"]     <- "classic"
cards <- filter(cards, type == "classic")

sum(is.na(cards))
```

## Clients

```{r}
sample_n(clients, 10)
```

In der Tabelle existiert die Spalte birth_number, welcher man auf den ersten Blick die Datumsräpresentation nicht ansieht.
In der Doku wird die Struktur deutlich, sie ist für Männer YYMMDD und für Frauen YYMMDD+50DD.
In Folge wird die Nummer in ihre Datumsräpresentation konvertiert und die Spalte "gender" als male/female aufgeschlüsselt.
Zudem wird das Alter der clients bezogen auf das Jahr 1999 herausextrahiert, da der Datensatz aus diesem Jahr stammt.
Es wird nicht year(Sys.Date()) verwendet, damit die Daten auch in Zukunft konsistent blieben.



```{r}
# Months above 12 must be female
clients <- mutate(clients, gender = 
                     ifelse(substr(birth_number, 3, 4) > 12, "female", "male"))

# Substract the 50 to get the birth month
clients <- mutate(clients, birth_month =
                     ifelse(as.numeric(substr(birth_number, 3, 4)) > 12,
                            as.numeric(substr(birth_number, 3, 4)) - 50,
                            as.numeric(substr(birth_number, 3, 4))))

# Transform the birth_number to a date
clients <- mutate(clients, birth_number = paste("19",
                                                substr(birth_number, 1, 2), 
                                                str_pad(birth_month, 2,
                                                        pad = "0"),
                                                substr(birth_number, 5, 6),
                   sep = "", collapse = NULL))
clients$birth_date <- as.Date(as.character(clients$birth_number),
                               format= "%Y%m%d")

# Remove unused columns
clients$birth_month <- NULL
clients$birth_number <- NULL

# Get the age of the clients in the year 1999 and save it in a column
get_age <- function(birth_date) {
  base_year <- 99
  year <- substr(birth_date, 3, 4)
  result <- base_year - as.integer(year)
  
  return(result)
}
clients <- clients %>%
   mutate(age = get_age(birth_date))

sum(is.na(clients))
```
```{r}
accounts
clients
```



## Dispositions

```{r}
sample_n(dispositions, 5)
```

Bei Dispositions sollen nur Owners verwendet werden, da die Analyse nur Eigentümer von Konten behandeln soll.

```{r}
dispositions <- dispositions %>% filter(type == 'OWNER')

sum(is.na(dispositions))
```

## Districts

Bei district sind die Spaltennamen der Tabelle abhanden gekommen.
Hier werden die Tabellennamen umbenannt, gemäss Doku.

```{r}
districts <- rename(districts, district_id = A1, district_name = A2, region = A3, 
                   inhabitants = A4, municipalities_inhabitants_smaller_499 = A5, 
                   municipalities_inhabitants_500_to_1999 = A6, 
                   municipalities_inhabitants_2000_to_9999 = A7, 
                   municipalities_inhabitants_larger_10000 = A8, cities = A9, 
                   urban_inhabitants_ratio = A10, average_salary = A11,
                   unemployment_rate_95 = A12, unemployment_rate_96 = A13,
                   entrepreneurs_per_1000 = A14, crimes_95 = A15,
                   crimes_96 = A16)

sum(is.na(districts))
```

## Transactions

```{r}
sample_n(transactions, 5)
```


In den Transaktionen muss das Datum gemäss Format YYMMDD konvertiert werden.

```{r}
# Rename k_symbol
transactions <- rename(transactions, c("characterization" = "k_symbol")) 

# Change formats
transactions$date <- as.Date(as.character(transactions$date), format= "%y%m%d")
transactions$amount <- as.numeric(transactions$amount)
transactions$balance <- as.numeric(transactions$balance)

# Translate values
transactions$type[transactions$type == "PRIJEM"] <- "credit"
transactions$type[transactions$type == "VYDAJ"]  <- "withdrawal"
transactions$type[transactions$type == "VYBER"]  <- "withdrawal"

transactions$operation[transactions$operation == "VKLAD"]          <- "cash credit"
transactions$operation[transactions$operation == "PREVOD Z UCTU"]  <- "collection"
transactions$operation[transactions$operation == "VYBER"]          <- "cash withdrawal"
transactions$operation[transactions$operation == " "]              <- "unknown"
transactions$operation[transactions$operation == "PREVOD NA UCET"] <- "remittance"
transactions$operation[transactions$operation == "VYBER KARTOU"]   <- "card withdrawal"

transactions$characterization[transactions$characterization == " "] <- "unknown"
transactions$characterization[transactions$characterization == "DUCHOD"] <- "pension"
transactions$characterization[transactions$characterization == "UROK"] <- "interest"
transactions$characterization[transactions$characterization == "SIPO"] <- "household"
transactions$characterization[transactions$characterization == "SLUZBY"] <- "payment statement"
transactions$characterization[transactions$characterization == "POJISTNE"] <- "insurance"
transactions$characterization[transactions$characterization == "SANKC. UROK"]  <- "neg_interest"
transactions$characterization[transactions$characterization == "UVER"]  <- "loan_pay"

sum(is.na(transactions))
```

## Orders

```{r}
sample_n(orders, 5)
```

```{r}
# Rename column k_symbol
orders <- rename(orders, "characterization" = "k_symbol") 

# Translate column characterization
orders$characterization[orders$characterization == "SIPO"]     <- "household"
orders$characterization[orders$characterization == "UVER"]     <- "loan"
orders$characterization[orders$characterization == "POJISTNE"] <- "insurance"
orders$characterization[orders$characterization == "LEASING"]  <- "leasing"

# Categorize NA as unknown
orders$characterization[is.na(orders$characterization)] <- "unknown"

orders$amount <- as.numeric(orders$amount)

sum(is.na(loans))
```


## Loans

```{r}
sample_n(loans, 5)
```

```{r}
loans$date <- as.Date(as.character(loans$date), format= "%y%m%d")
loans$payments <- as.numeric(loans$payments)
loans$amount <- as.numeric(loans$amount)

# Make column status human readable
loans$status[loans$status == "A"] <- "finished_payed"
loans$status[loans$status == "B"] <- "finished_not_payed"
loans$status[loans$status == "C"] <- "running_ok"
loans$status[loans$status == "D"] <- "running_in_debt"

sum(is.na(loans))
```


# Zusammenfügen der Dataframes

In diesem Abschnitt werden die verschiedenen Tabellen zusammen gesetzt.
Dabei werden loan, cards und district it left join angehängt, damit fehlende Spalten nicht den Datensatz verkleinern.
Die Transaktionsdaten werden hier noch nicht zusammengeführt.

```{r}
# Clients mit dispositions
full <- inner_join(clients, dispositions, by = "client_id", suffix = c(".client", ".dispositions"))
sum(duplicated(full$client_id))

# Full mit account
full <- inner_join(full, accounts, by = "account_id", suffix = c("", ".accounts"))
sum(duplicated(full$account_id))

# Full mit loan
sum(duplicated(loans$account_id))
full <- left_join(full, loans, by = "account_id", suffix = c("", ".loans"))

# Full mit cards
full <- left_join(full, cards, by = "disp_id", suffix = c("", ".cards"))
sum(duplicated(cards$disp_id))

# District Informations for client
full <- left_join(full, districts, by = "district_id")

# District informations for card
full <- left_join(full, districts, by = c("district_id.accounts"="district_id"), suffix = c("", ".accounts"))

sample_n(full, 5)
```

Jugendliche und Personen, welche während des Zeitraums des Datensatzes erst erwachsen worden sind, sollen nicht in die Auswertung einfliessen.
Da sicher der Datensatz über einen Zeitraum von sechs Jahren erstreckt werden alle Clients jünger als 25 Jahre herausgefiltert.

```{r}
full <- full %>% filter(age >= 25)
```

```{r}
full
```
Somit bleiben uns 3858 Kunden.

# Trennung Buyer / Nicht-Buyer


Als nächstes werden alle Zeilen mit Kreditkartenkäufern von den Nicht-Käufern getrennt.


```{r}
has_card_function <- function(x) {
  if (is.na(x)) {
    return(FALSE)
  } else {
    return(TRUE)
  }
}

full$has_card <- sapply(full[, "card_id"], has_card_function)
full <- full %>% select(-card_id, -type.cards)

card_buyers <- full %>% filter(has_card == TRUE)

non_buyers <- full %>% filter(has_card == FALSE)
```


# Ermitteln der Differenz der Transaktionen

```{r}
sample_n(transactions, 5)
```


Bei den Transaktionen ist jeweils die neue Balance und der Betrag der Transaktion angegebn. Das Problem dabei ist, dass alle Beträge positiv sind, auch wenn sie eigentlich abgezogen werden. 

```{r}
df <- transactions

# Konvertieren Sie das 'date'-Feld in ein Datum
df$date <- as.Date(df$date)

# Sortieren Sie das Dataframe nach Nutzer und Datum
df <- df[order(df$account_id, df$date), ]

# Gruppieren Sie das Dataframe nach Nutzer
df <- group_by(df, account_id)

# Iterieren Sie über jeden Nutzer und bearbeiten Sie die Transaktionen
df <- df %>% 
  summarize(transactions = {
    # Fügen Sie eine Spalte mit dem vorherigen Kontostand hinzu
    prev_balance <- ifelse(row_number() == 1, NA, lag(balance, order_by = date))

    # Berechnen Sie den Unterschied zwischen dem vorherigen Kontostand und dem aktuellen Kontostand
    difference <- balance - prev_balance

    # Erstellen Sie das Dataframe mit den Transaktionen für jeden Nutzer
    transactions_df <- data.frame(amount, date, balance, prev_balance, difference)
    transactions_df
  }) %>%
  ungroup()

transactions <- unnest(df, transactions)

# Hinzufügen des ersten amounts bei jedem Account
transactions$difference <- ifelse(is.na(transactions$difference) & is.na(transactions$prev_balance) & (transactions$amount == transactions$balance), transactions$amount, transactions$difference)

#transactions$amount <- NULL

sample_n(transactions, 5)
```

```{r}
transactions[transactions$amount != abs(transactions$difference), ]
```


# Zusammenfassen der Transaktionen für Card Buyers

Um die Transaktions-Daten in unseren Modellen brauchen zu können, muss für jeden Kunde ein Rollup-Fenster erstellt werden. Dies fasst die Transaktionen der zwölf Monate vor dem Erhalt einer Kreditkarte zusammen (minus einen Monat Input Lag). Auf diesen Monaten werden die Transaktionen zusammengefasst.

Als erstes werden die Transaktionen von Kunden herausgefiltert, welche eine Kreditkarte haben.

```{r}
account_ids <- card_buyers$account_id
buyer_transactions <- transactions[transactions$account_id %in% account_ids,]
```

Das issued-Datum soll zu den Transaktionen hinzugefügt werden, damit diese für jeden Kunden einzeln gefiltert werden können.

```{r}
buyer_transactions <- merge(buyer_transactions, full[, c("account_id", "issued")], by="account_id")
```

Nun sollen Transaktionen so gefiltert werden, dass nur noch Transaktionen zwischen 13 Monaten und 1 Monat vor dem Issued Datum vorkommen.

```{r}
filtered_df <- buyer_transactions %>%
  filter(date >= as.Date(paste0(format(issued - months(13), "%Y-%m"), "-01")) &
         date <= as.Date(paste0(format(issued - months(1), "%Y-%m"), "-01")) - 1)
```

Auf diesen Daten wird eine Gruppierung anhand der account_id und des Monats gemacht werden. Die Werte in difference und balance werden zu verschiedenen Metriken zusammengefasst:
Auf beiden Werten erfassen wir das Minimum, das Maximum, den Durchschnitt, den Median und die Standardabweichung. Bei der balance erfassen wir die erste und die letzte Balance des Monats und bei difference die Anzahl positive und negative differences.

```{r}
summary_df <- filtered_df %>%
  group_by(account_id, month = format(date, "%Y-%m")) %>%
  summarise(
    max_difference = max(difference),
    min_difference = min(difference),
    max_balance = max(balance),
    min_balance = min(balance),
    initial_balance = first(balance),
    end_balance = last(balance),
    mean_balance = mean(balance),
    median_balance = median(balance),
    std_balance = sd(balance),
    mean_difference = mean(difference),
    median_difference = median(difference),
    std_difference = sd(difference),
    count_positive_difference = sum(difference > 0),
    count_negative_difference = sum(difference < 0)
  )
summary_df <- summary_df %>%
  arrange(account_id)
summary_df
```

Jetzt haben wir für jede account_id eine Übersicht über die 12 Monate vor dem Kartenerhalt. Da es aber sein könnte, dass es Kunden gibt, welche nicht jeden Monat eine Transaktion hatten oder die Kreditkarte bereits im ersten Jahr erhalten haben, kontrollieren wir dies noch.

```{r}
# Kontrolle, ob für jeden account_id 12 monate vorhanden sind
month_counts <- summary_df %>%
  group_by(account_id) %>%
  summarise(month_count = n_distinct(month))

# Prüfe, ob jedes account_id 12 Monate hat
month_counts <- month_counts %>% filter(month_count != 12)
month_counts

```
162 Kunden haben also keine 12 kontinuierlichen Monate mit Transaktionen, bevor sie eine Karte bekommen. Wir filtern diese Kunden raus.

```{r}
summary_df <- subset(summary_df, !account_id %in% month_counts$account_id)
```

Als nächstes nummerieren wir die Monate pro account_id von 1 bis 12 durch, um danach weiter damit arbeiten zu können.

```{r}
# Sortieren nach account_id und Monat
summary_df <- summary_df[order(summary_df$account_id, rev(summary_df$month)),]

# Hinzufügen der Monatsnummer
summary_df$group_id <- ave(seq_along(summary_df$account_id), summary_df$account_id, FUN = function(x) {x})
summary_df$month_number <- 12

for (i in 2:nrow(summary_df)) {
  if (summary_df$account_id[i] != summary_df$account_id[i-1]) {
    summary_df$month_number[i] <- 12
  } else {
    summary_df$month_number[i] <- summary_df$month_number[i-1] - 1
  }
}

# Entferne die Spalte group_id
summary_df$group_id <- NULL
summary_df$month <- NULL
```

Nun möchten wir alle Informationen pro account_id auf einer Zeile haben. Dafür brauchen wir pivot_wider. So haben wir jede Kennzahl zwölf mal als Kolonne, jedes Mal mit der vorher erstellten Monatsnummer als Suffix.

```{r}
summary_df_buyers <- summary_df %>%
  group_by(account_id) %>%
  pivot_wider(names_from = month_number,
              values_from = c(max_difference, min_difference, max_balance, min_balance, initial_balance, end_balance, mean_balance, median_balance, std_balance, median_balance, std_balance, mean_difference, median_difference, std_difference, count_positive_difference, count_negative_difference))

summary_df_buyers <- merge(summary_df_buyers, card_buyers, by = "account_id")
```

```{r}
summary_df_buyers
```


# Finden von ähnlichen Nutzern

Zu jedem Kartenkäufer soll nun ein ähnlicher Nichtkäufer gefunden werden

```{r}
# Erstelle ein leeres DataFrame "similar_non_buyers"
similar_non_buyers <- data.frame()

# Iteriere über jeden Kunden im DataFrame "buyers"
for (i in 1:nrow(card_buyers)) {
  # Wähle den aktuellen Kunden aus dem DataFrame "buyers"
  current_buyer <- card_buyers[i, ]
  
  # Wähle die Kunden aus dem DataFrame "non_buyers" aus, die das gleiche Geschlecht haben und möglichst gleich alt sind und möglichst in der gleichen Region wohnen
  similar_non_buyers_temp <- non_buyers %>%
    filter(gender == current_buyer$gender,
           abs(age - current_buyer$age) <= 5,
           region == current_buyer$region)
  
  # Wähle den am besten passenden Kunden aus "similar_non_buyers_temp" aus
  best_match_index <- which.min(abs(similar_non_buyers_temp$age - current_buyer$age))
  best_match <- similar_non_buyers_temp[best_match_index, ]
  best_match$issued <- current_buyer$issued
  
  # damit nicht der gleiche non_buyer doppelt verwendet wird
  non_buyers <- non_buyers %>% filter(client_id != best_match$client_id)
  
  
  similar_non_buyers <- rbind(similar_non_buyers, best_match)
  
}
```


# Zusammenfassen der Transaktionen für non buyers

Auch hier sollen die Transaktionen gleich wie bei den Käufern zusammengefasst werden.

```{r}
account_ids <- similar_non_buyers$account_id
non_buyer_transactions <- transactions[transactions$account_id %in% account_ids,]

non_buyer_transactions <- merge(non_buyer_transactions, similar_non_buyers[, c("account_id", "issued")], by="account_id")

```
```{r}
filtered_df <- non_buyer_transactions %>%
  filter(date >= as.Date(paste0(format(issued - months(13), "%Y-%m"), "-01")) &
         date <= as.Date(paste0(format(issued - months(1), "%Y-%m"), "-01")) - 1)
```
```{r}
summary_df <- filtered_df %>%
  group_by(account_id, month = format(date, "%Y-%m")) %>%
  summarise(
    max_difference = max(difference),
    min_difference = min(difference),
    max_balance = max(balance),
    min_balance = min(balance),
    initial_balance = first(balance),
    end_balance = last(balance),
    mean_balance = mean(balance),
    median_balance = median(balance),
    std_balance = sd(balance),
    mean_difference = mean(difference),
    median_difference = median(difference),
    std_difference = sd(difference),
    count_positive_difference = sum(difference > 0),
    count_negative_difference = sum(difference < 0)
  )
summary_df <- summary_df %>%
  arrange(account_id)
```

```{r}
# Kontrolle, ob für jeden account_id 12 monate vorhanden sind
month_counts <- summary_df %>%
  group_by(account_id) %>%
  summarise(month_count = n_distinct(month))

# Prüfe, ob jedes account_id 12 Monate hat
month_counts <- month_counts %>% filter(month_count != 12)
month_counts
```
Auch hier haben wieder einige Kunden weniger als 12 kontinuierliche Monate.

```{r}
summary_df <- subset(summary_df, !account_id %in% month_counts$account_id)
```


```{r}
summary_df <- summary_df[order(summary_df$account_id, rev(summary_df$month)),]
summary_df$group_id <- ave(seq_along(summary_df$account_id), summary_df$account_id, FUN = function(x) {x})

summary_df$month_number <- 12

for (i in 2:nrow(summary_df)) {
  if (summary_df$account_id[i] != summary_df$account_id[i-1]) {
    summary_df$month_number[i] <- 12
  } else {
    summary_df$month_number[i] <- summary_df$month_number[i-1] - 1
  }
}

# Entferne die Spalte group_id
summary_df$group_id <- NULL
summary_df$month <- NULL
```

```{r}
summary_df
```


```{r}
summary_df_non_buyers <- summary_df %>%
  group_by(account_id) %>%
  pivot_wider(names_from = month_number,
              values_from = c(max_difference, min_difference, max_balance, min_balance, initial_balance, end_balance, mean_balance, median_balance, std_balance, median_balance, std_balance, mean_difference, median_difference, std_difference, count_positive_difference, count_negative_difference))
```

Die Transaktionsdaten werden mit den anderen Daten zusammengefügt, um pro Kunde eine Zeile in einem Dataframe zu haben.

```{r}
summary_df_non_buyers <- merge(summary_df_non_buyers, similar_non_buyers, by = "account_id")
```


```{r}
final_df <- rbind(summary_df_buyers, summary_df_non_buyers)
```

Jetzt muss noch dass issued-Datum sowie weitere Variabeln entfernt werden.

```{r}
# Entferne weitere unnötige Variabeln wie ID's oder Werte, welche überall gleich sind
final_df <- final_df %>% select(-client_id, -district_id, -district_id.accounts, -disp_id, -type, -loan_id, -account_id, -issued)
```

Ausserdem scheinen einige Variabeln als Faktoren im Datensatz zu sein, welche eigentlich numerisch wären.

```{r}
final_df$unemployment_rate_95 <- as.numeric(final_df$unemployment_rate_95)
final_df$unemployment_rate_95.accounts <- as.numeric(final_df$unemployment_rate_95.accounts)
final_df$crimes_95 <- as.numeric(final_df$crimes_95)
final_df$crimes_95.accounts <- as.numeric(final_df$crimes_95.accounts)
```
# EDA

```{r}
ggplot(data = final_df, aes(x = has_card)) +
  geom_bar(aes(y = ..count..), stat = "count", fill = "steelblue") +
  labs(x = "Has Card", y = "Frequency")
```
```{r}
# Durchschnittliche Werte für has_card == TRUE berechnen
averages_true <- colMeans(final_df[final_df$has_card == TRUE,
                                   c("median_balance_1", "median_balance_2", "median_balance_3",
                                     "median_balance_4", "median_balance_5", "median_balance_6",
                                     "median_balance_7", "median_balance_8", "median_balance_9",
                                     "median_balance_10", "median_balance_11", "median_balance_12")])

# Durchschnittliche Werte für has_card == FALSE berechnen
averages_false <- colMeans(final_df[final_df$has_card == FALSE,
                                    c("median_balance_1", "median_balance_2", "median_balance_3",
                                      "median_balance_4", "median_balance_5", "median_balance_6",
                                      "median_balance_7", "median_balance_8", "median_balance_9",
                                      "median_balance_10", "median_balance_11", "median_balance_12")])

# Line Plot erstellen
ggplot() +
  geom_line(aes(x = 1:12, y = averages_true), color = "steelblue") +
  geom_line(aes(x = 1:12, y = averages_false), color = "red") +
  labs(x = "Month", y = "Average Median Balance") +
  scale_color_manual(name = "", values = c("steelblue" = "Buyers", "red" = "Non Buyers"))
```


# Modelle

Als nächstes sollen Modelle trainiert und evaluiert werden. Um die Resultate zu reproduzieren, wird hier ein initialier seed gesetzt.

```{r}
set.seed(27)
```


## Funktionen zur Evaluierung von Modellen

### Train-Test-Split

Als Vorbereitung für die Modelle müssen wir unsere Daten zu Trainings- und Testdaten unterteilen. Dafür erstellen wir eine Funktion, welche auf verschiedenen Varianten des Datensatz gebraucht werden kann.

```{r}
split_data <- function(df, test_size = 0.2) {
  split <- createDataPartition(df$has_card, p = 1 - test_size, list = FALSE)
  train <- df[split, ]
  test <- df[-split, ]
  
  return(list(train = train, test = test))
}
```

### Metriken

Damit wir die verschiedenen Modelle besser evaluieren können, müssen wir die gleichen Kennzahlen und Auswertungen pro Modell machen. Zu diesem Zweck definieren wir einige Funktionen, damit wir weniger redundanten Code haben und unsere Ergebnisse in einem einheitliche, vergleichbaren Format daherkommen. 

Dafür erstellen wir eine Funktion, die die Genauigkeit (Accuracy), Cohen's Kappa, Matthews Korrelation, Präzision (Precision), Erinnerung (Recall) und den F1-Score für eine Reihe von Vorhersagen und deren entsprechenden wahren Werte berechnet.

Was bedeuten diese Kennzahlen genau?

Accuracy (Genauigkeit): Die Accuracy ist der Prozentsatz der Vorhersagen, die mit den tatsächlichen Werten übereinstimmen. Sie wird berechnet als Anzahl der korrekten Vorhersagen geteilt durch die Gesamtzahl der Vorhersagen.

Cohen's Kappa (Cohen's Kappa): Cohen's Kappa ist eine Messgröße für die Qualität von binären Klassifikationen. Es wird verwendet, um die Übereinstimmung zwischen zwei Klassifikatoren zu messen, indem es die Übereinstimmung über der erwarteten Übereinstimmung durch Zufall berechnet. Ein Kappa-Wert von 1 bedeutet perfekte Übereinstimmung, ein Wert von 0 bedeutet keine Übereinstimmung, die besser ist als Zufall, und ein Wert von -1 bedeutet komplett falsche Klassifikationen.

Matthews correlation coefficient (Matthews Korrelation): Der Matthews Korrelation Coefficient (MCC) ist eine Messgröße für die Qualität von binären Klassifikationen. Er reicht von -1 bis 1, wobei ein Wert von 1 perfekte Klassifikation bedeutet, ein Wert von 0 eine Klassifikation, die nicht besser als Zufall ist, und ein Wert von -1 eine komplett falsche Klassifikation bedeutet.

Precision (Präzision): Die Präzision ist der Prozentsatz der Vorhersagen, die tatsächlich korrekt waren, unter der Annahme, dass alle Vorhersagen korrekt sind. Sie wird berechnet als Anzahl der korrekten Vorhersagen für die positive Klasse geteilt durch die Gesamtzahl der Vorhersagen für die positive Klasse.

Recall (Erinnerung): Der Recall ist der Prozentsatz der tatsächlich positiven Werte, die korrekt vorhergesagt wurden. Er wird berechnet als Anzahl der korrekten Vorhersagen für die positive Klasse geteilt durch die Gesamtzahl der tatsächlich positiven Werte.

F1 score (F1-Wert): Der F1-Wert ist ein Maß für die Qualität von binären Klassifikationen, das die Harmoniesche Mischung von Präzision und Recall darstellt. Es wird berechnet als der Harmoniesche Mittelwert von Präzision und Recall. Ein hoher F1-Wert bedeutet, dass sowohl Präzision als auch Recall hoch sind.

```{r}
get_metrics <- function(predictions, true_values) {
  # Calculate accuracy
  accuracy <- sum(predictions == true_values) / length(predictions)
  
  # Calculate Cohen's kappa
  n <- length(predictions)
observed_agreement <- sum(predictions == true_values)
expected_agreement <- sum(predictions == true_values) / n
kappa <- (observed_agreement - expected_agreement) / (n - expected_agreement)
  
  # Calculate Matthews correlation coefficient
  confusion_matrix <- table(predictions, true_values)
  tp <- confusion_matrix[2,2]
  tn <- confusion_matrix[1,1]
  fp <- confusion_matrix[2,1]
  fn <- confusion_matrix[1,2]
  matthews <- (tp * tn - fp * fn) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
  
  # Calculate precision and recall
  precision <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
  recall <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
  
  # Calculate F1 score
  f1 <- 2 * (precision * recall) / (precision + recall)
  
  # Create a data frame of the metrics
  metrics <- data.frame(accuracy = accuracy, kappa = kappa, matthews = matthews,
                        precision = precision, recall = recall, f1 = f1)
  
  # Return the data frame
  return(metrics)
}
```

### Konfusionsmatrix mit Plot

Diese Funktion erstellt eine Konfusionsmatrix und gibt sie als Plot zurück. 

Eine Konfusionsmatrix ist ein wichtiges Werkzeug zur Evaluation von Klassifikationsmodellen. Sie zeigt an, wie gut das Modell in der Lage ist, die verschiedenen Klassen richtig zu identifizieren. In einer Konfusionsmatrix werden die tatsächlichen und die von dem Modell vorhergesagten Klassen gegenübergestellt. Die Matrix ist in vier Quadranten unterteilt: true positives (TP), true negatives (TN), false positives (FP) und false negatives (FN). TP sind die Fälle, in denen das Modell die Klasse richtig vorhergesagt hat, TN sind die Fälle, in denen das Modell die Klasse richtig vorhergesagt hat und diese Klasse auch tatsächlich vorliegt, FP sind die Fälle, in denen das Modell eine Klasse vorhergesagt hat, die in Wirklichkeit nicht vorliegt, und FN sind die Fälle, in denen das Modell eine Klasse nicht vorhergesagt hat, die in Wirklichkeit vorliegt. Eine Konfusionsmatrix ist hilfreich, um die Genauigkeit, Sensitivität und Spezifität des Modells zu berechnen und um zu sehen, an welchen Stellen das Modell Schwächen hat. Sie kann auch verwendet werden, um die Leistung von verschiedenen Modellen miteinander zu vergleichen.

```{r}
plot_confusion_matrix <- function(predictions, true_values) {
  # Erstelle eine Confusion Matrix als Data Frame
  confusion_matrix_df <- data.frame(predictions, true_values)
  
  # Zähle die Häufigkeiten jeder Kombination von Vorhersage- und True-Werten
  counts_df <- count(confusion_matrix_df, predictions, true_values)
  
  # Erstelle einen ggplot-Plot
  ggplot(data = counts_df, aes(x = predictions, y = true_values)) +
    geom_tile(aes(fill = n)) +
    geom_text(aes(label = n)) +
    scale_fill_gradient(low = "white", high = "darkgreen") +
    labs(x = "Predicted Class", y = "True Class", title = "Confusion Matrix")
}
```

### ROC / AUC

Diese Funktion zeichnet die ROC-Kurve und berechnet die Area und Curve. 

Die ROC-Kurve (Receiver Operating Characteristic curve) ist ein wichtiges Werkzeug zur Bewertung von Klassifikatoren. Sie zeigt die Leistung des Klassifikators bei verschiedenen Schwellenwerten an, die zur Unterscheidung zwischen zwei Klassen verwendet werden. Die ROC-Kurve ist besonders nützlich, wenn die beiden Klassen im Verhältnis unausgeglichen sind, wie es oft der Fall ist, wenn es darum geht, seltene Ereignisse wie Krankheiten oder Betrug zu erkennen.

Die ROC-Kurve ist auf der x-Achse der falsch-positiv-Rate (FPR) und auf der y-Achse der wahr-positiv-Rate (TPR) aufgetragen. Der FPR gibt an, wie viele falsch positive Ergebnisse es gibt, während der TPR angibt, wie viele wahr positive Ergebnisse erzielt werden. Ein perfekter Klassifikator würde eine ROC-Kurve haben, die im oberen linken Bereich beginnt und nach rechts oben verläuft, wobei alle Fälle korrekt klassifiziert werden. Ein zufälliger Klassifikator würde eine diagonal verlaufende ROC-Kurve haben, da die FPR und TPR zufällig verteilt sind.

Die AuC (Area Under the Curve) ist eine Metrik, die aus der ROC-Kurve berechnet wird und die Leistung des Klassifikators zusammenfasst. Sie gibt an, wie gut der Klassifikator im Vergleich zu einem zufälligen Klassifikator ist. Eine AUC von 1 bedeutet, dass das Modell perfekt in der Lage ist, positive und negative Klassen zu unterscheiden, während eine AUC von 0.5 bedeutet, dass das Modell keine bessere Leistung als Zufall erzielt. Die AUC kann Werte zwischen 0 und 1 annehmen. Eine AUC von 0 bedeutet, dass das Modell völlig inkorrekt ist. Im Allgemeinen gilt, je größer die AUC, desto besser ist das Modell im Vergleich zu anderen Modellen.

```{r}
make_roc_plot_and_get_auc <- function(predictions, true_values){

roc_curve <- roc(as.numeric(predictions), as.numeric(true_values) - 1)

plot(roc_curve, xlab = "False Positive Rate", ylab = "True Positive Rate", main ="ROC Curve")

auc <- auc(roc_curve)

return(auc)
}
```


### Feature Importance

Um die Feature Importance genauer zu untersuchen, definieren wir eine Funktion, welche für ein Modell die Feature Importance berechnet und die Top 10 Features in einem Barplot ausgibt.Die Funktion plot_feature_importance() nimmt als Eingabeparameter ein maschinelles Lernmodell und plottet die Feature-Importance des Modells als Barplot. Die Funktion unterscheidet drei Arten von Modellen: Logistische Regressionen, Entscheidungsbäume und Random Forest. Für jede Art von Modell wird die Feature-Importance auf eine spezifische Art und Weise berechnet. Anschließend werden die Feature-Importance-Werte und die Namen der Features absteigend sortiert, wobei nur die 10 wichtigsten Features berücksichtigt werden. Der Barplot zeigt dann die Feature-Importance-Werte für die entsprechenden Features an. Der Titel des Plots lautet "Feature Importance" und die y-Achse ist mit "Importance" beschriftet. Die Namen der Features werden rotiert angezeigt, um Platz zu sparen, und die Farben der einzelnen Features sind unterschiedlich.

```{r}
plot_feature_importance <- function(model) {
  
  # Logistische Regression
  if (class(model)[1] == "glm") {
    importance <- abs(coef(model)[-1])
    names <- names(importance)
    
    # Sort feature importance and names in decreasing order
  importance <- head(importance[order(importance, decreasing = TRUE)], 10)
  names <- names[order(importance, decreasing = TRUE)]
  } 
  
  # Random Forest
  else if (class(model)[1] == "randomForest") {
    importance <- model$importance
    names <- row.names(importance)
  } 
  
  # Unrecognized model
  else {
    stop("Unrecognized model")
  }
  
  
  
  # Plot feature importance
  barplot(importance, names.arg = names, las = 2, cex.names = 0.6,
          main = "Feature Importance", xlab = "", ylab = "Importance")
}
```

### Threshold Plot

```{r}

find_best_threshold <- function(predictions, actual_values) {
best_threshold <- 0
best_f1 <- 0
thresholds <- seq(0.01, 0.99, 0.01)
f1_scores <- rep(0, length(thresholds))

for (i in 1:length(thresholds)) {
  # Set the threshold for the predictions
  predictions_threshold <- ifelse(predictions > thresholds[i], TRUE, FALSE)
  
  if (all(predictions_threshold)) {
  next
} else if (all(!predictions_threshold)) {
  next
}
  
  # Calculate the f1
  f1 <- get_metrics(predictions_threshold, actual_values)$f1
  
  f1_scores[i] <- f1
  
  # Update the best threshold and best f1 if necessary
  if (f1 > best_f1) {
    best_threshold <- thresholds[i]
    best_f1 <- f1
  }
}

# Display the best threshold and best recall
print(paste("Best threshold:", best_threshold))
print(paste("Best F1:", best_f1))

plot(thresholds, f1_scores, type = "l", xlab = "Threshold", ylab = "F1 Score", main = "F1 Score with different thresholds")

return(best_threshold)
}
```

# Baseline Modell

Als erstes soll eine logistische Regression mit den Informationen Alter, Geschlecht, Domizilregion, Vermögen (balance-Schnitt über alle Monate) und Umsatz (difference-Schnitt über alle Monate) als Baseline Modell erstellt werden.Dafür müssen wir kurz ein neues Dataframe erstellen.

```{r}
baseline_data <- final_df
baseline_data$mean_balance <- rowMeans(final_df[, c("mean_balance_1", "mean_balance_2", "mean_balance_3", "mean_balance_4", 
                                                "mean_balance_5", "mean_balance_6", "mean_balance_7", "mean_balance_8", 
                                                "mean_balance_9", "mean_balance_10", "mean_balance_11", "mean_balance_12")])
baseline_data$mean_difference <- rowMeans(final_df[, c("mean_difference_1", "mean_difference_2", "mean_difference_3", "mean_difference_4", 
                                                  "mean_difference_5", "mean_difference_6", "mean_difference_7", "mean_difference_8", 
                                                  "mean_difference_9", "mean_difference_10", "mean_difference_11", "mean_difference_12")])
baseline_data <- baseline_data[, c("age", "gender", "region", "has_card", "mean_balance", "mean_difference")]
baseline_data$has_card <- as.factor(baseline_data$has_card)
```

Darauf wird ein Train-Test-Split mit 80% Trainingsdaten und 20% Testdaten gebraucht.
 
```{r}
splits <- split_data(baseline_data, test_size = 0.2)
train <- splits$train
test <- splits$test
```

Das Regressionsmodell wird auf den Trainingsdaten trainiert.

```{r}
# Fit the model on the training data
model <- glm(has_card ~ ., data = train, family = binomial)
```

Als nächstes sollen die Predictions gemacht und damit die Metriken erstellt werden. Da die logistische Regression eine Zahl zwischen 0 und 1 zurückgibt, müssen wir anhand eines Thresholds die Werte zu TRUE und FALSE umwandeln. Der Threshold gibt an, ab welchem Wahrscheinlichkeitswert eine Vorhersage als positiv betrachtet wird. Standardmäßig ist der Threshold auf 0.5 gesetzt, was bedeutet, dass alle Wahrscheinlichkeiten größer als 0.5 als positiv und alle Wahrscheinlichkeiten kleiner als 0.5 als negativ betrachtet werden.

```{r}
# Make predictions on the test data
predictions <- predict(model, test, type = "response")

threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)


get_metrics(predictions_threshold, test$has_card)
```

```{r}
plot_confusion_matrix(predictions_threshold, test$has_card)
```

```{r}
make_roc_plot_and_get_auc(predictions_threshold, test$has_card)
```

```{r}
plot_feature_importance(model)
```


## Threshold 

Der Threshold-Wert könnte aber angepasst werden. Je nach Veränderung werden die verschiedenen Metriken besser oder schlechter. Die Frage dabei ist, ob wir eher mehr falsche Positivvorhersagen oder Negativvorhersagen wollen. Wenn wir den Threshold senken, wird bspw. der Recall höher. Wenn wir den Threshold erhöhen, wird die Precision höher. Es ist aber nicht sinnvoll, anhand des Thresholds diese beiden Metriken zu maximieren, da es bei beiden fast keine Positiven bzw. Negative Predictions mehr gibt. 

Der F1 ist eine Zusammenfassung der Precision und der Recall. Wir untersuchen, mit welchem Threshold der höchste F1-Score erzielt werden kann.

```{r}
best_threshold <- find_best_threshold(predictions, test$has_card)
```

Wie sehen die anderen Metriken mit diesem Threshold aus?

```{r}
predictions_threshold <- ifelse(predictions > best_threshold, TRUE, FALSE)
get_metrics(predictions_threshold, test$has_card)
```


# Regressionsmodell mit allen Daten

Nun soll dieses Baseline-Modell verbessert werden. Als erstes probieren wir, das gleiche Modell (Logistische Regression) mit mehr Input-Parametern zu trainieren. 

Da die logistische Regression Probleme mit Faktoren hat, welche nur im Trainings- bzw. Testdatensatz vorkommen und auch nicht gut mit NA's umgehen kann, müssen wir zuerst noch einige Anpassungen am Datensatz vornehmen.

Als erstes entfernen wir alle Kolonnen, welche Faktoren sind und mehr als 10 verschiedene Ausprägungen haben.

```{r}
# Ermittle die numerischen Merkmale in den Trainingsdaten
numeric_vars <- sapply(final_df, is.numeric)

# Erstelle ein Subset der Trainingsdaten ohne die numerischen Merkmale
train_no_numeric <- final_df[, !numeric_vars]

# Ermittle die Anzahl der Kategorien für jedes Merkmal
num_categories <- sapply(train_no_numeric, function(x) length(unique(x)))

# Überprüfe, ob ein Merkmal zu viele Kategorien hat
too_many_categories <- num_categories > 10

# Gib die Namen der Merkmale aus, die zu viele Kategorien haben
columns_to_remove <- colnames(train_no_numeric)[too_many_categories]


# Ermittle die Spaltennamen, die behalten werden sollen
keep_columns <- setdiff(colnames(final_df), columns_to_remove)

# Erstelle ein Subset des Dataframes mit den behaltenen Spaltennamen
final_df_simplified <- final_df[, keep_columns]

columns_to_remove
```

Nun muss der Datensatz noch auf NA's überprüft werden.

```{r}
# Count the number of NA values in the data frame
num_na <- sum(is.na(final_df_simplified))

# Print the total number of NA values
print(paste("Total number of NA values:", num_na))

# Create a logical vector indicating whether each element is NA
na_matrix <- is.na(final_df_simplified)

# Sum the number of NA values per row
na_counts <- rowSums(na_matrix)

# Count the rows with NA values
num_na_rows <- sum(na_counts > 0)

# Print the number of rows with NA values
print(paste("Number of rows with NA values:", num_na_rows))

# Sum the number of NA values per column
na_counts_cols <- colSums((na_matrix))

# Count the columns with NA values
num_na_cols <- sum(na_counts_cols > 0)

# Print the number of columns with NA values
print(paste("Number of columns with NA values:", num_na_cols))
```

Fast jede Zeile hat irgendwo ein NA. Es sind auch viele Kolonnen betroffen. Wir können also nicht alle Observationen oder Variabeln mit NA's entfernen, da sonst der Datenverlust sehr gross wäre. Daher imputieren wir die numerischen fehlenden Werte mit dem Median und die fehlenden kategorialen Werte mit dem Wert, welcher am meisten vorkommt.

```{r}
# Impute NA numbers with the median
final_df_simplified <- final_df_simplified %>% 
  mutate_if(is.numeric, list(~ if_else(is.na(.), median(., na.rm = TRUE), .)))

# Impute NA strings/factors with the most common value
final_df_simplified <- final_df_simplified %>% 
  mutate_if(is.character, list(~ if_else(is.na(.), mode(.), .)))
```

```{r}
sum(is.na(final_df_simplified))
```


```{r}
splits <- split_data(final_df_simplified, test_size = 0.2)
train <- splits$train
test <- splits$test
```

```{r}
# Fit the model on the training data
model <- glm(has_card ~ ., data = train, family = binomial)
```

```{r}
# Make predictions on the test data
predictions <- predict(model, test, type = "response")

threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

get_metrics(predictions_threshold, test$has_card)
```

```{r}
plot_confusion_matrix(predictions_threshold, test$has_card)
```

```{r}
make_roc_plot_and_get_auc(predictions_threshold, test$has_card)
```


```{r}
plot_feature_importance(model)
```

```{r}
find_best_threshold(predictions, test$has_card)
```

## Mit nur den beiden wichtigsten Variabeln

```{r}
final_df_simplified_two_variables <- final_df_simplified %>% select(max_difference_12, max_difference_11)
model <- glm(has_card ~ ., data = train, family = binomial)
predictions <- predict(model, test, type = "response")

threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

get_metrics(predictions_threshold, test$has_card)
```



# Decision Tree

```{r}

model <- rpart(has_card ~ ., data = train, method = "class")

# Make predictions on the test data (second column is for probability of true)
predictions <- predict(model, test, type = "prob")[, 2]

threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

get_metrics(predictions_threshold, test$has_card)
```

```{r}
plot_confusion_matrix(predictions_threshold, test$has_card)
make_roc_plot_and_get_auc(predictions_threshold, test$has_card)
find_best_threshold(predictions, test$has_card)
rpart.plot(model)
```


Die Klassifikation ist um einiges besser auf dem Decision Tree. Es scheint also für unseren Verwendungszweck der bessere Algorithmus zu sein. Wir untersuchen noch Erweiterungen des Decision Trees: der Random Forest.



# Random Forest 

Beim Random Forest muss unsere Zielvariabel noch in einen Faktor umgewandelt werden, damit die Wahrscheinlichkeiten vorhergesagt werden können.

```{r}
train$has_card <- as.factor(train$has_card)
# Fit a random forest model to the training data
model <- randomForest(has_card ~ ., data = train, method = "class")

# Make predictions on the test data (second column is for probability of true)
predictions <- predict(model, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
get_metrics(predictions_threshold, test$has_card)
```

Der Random Forest ist ein wenig besser als der Decision Tree. Als nächstes wollen wir probieren, ob eine Hyperparameteroptimierung unser Resultat noch verbessern kann.


```{r}
plot_confusion_matrix(predictions_threshold, test$has_card)
make_roc_plot_and_get_auc(predictions_threshold, test$has_card)
find_best_threshold(predictions, test$has_card)
```

```{r}
importance_values <- varImp(model)
importance_values$variable <- rownames(varImp(model)) 
importance_values <- importance_values[order(importance_values$Overall, decreasing = TRUE),]

# Wählen Sie die top 10 Merkmale aus
top_features <- head(importance_values, n = 10)
top_features

```

```{r}
# Initialize empty vector to store f1-scores
f1_scores <- c()

# Loop through each variable and fit a random forest model
for (i in 1:50) {
  # Select subset of variables
  vars_subset <- importance_values$variable[1:i]
  
  # Fit random forest model
  train_reduced <- train %>% select(has_card, vars_subset)
  model <- randomForest(has_card ~ ., data = train_reduced, method = "class")
  
  # Make predictions on test data
  predictions <- predict(model, test, type = "prob")[, 2]
  
  # Threshold predictions
  threshold <- 0.5
  predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)
  
  # Calculate f1-score
  f1 <- get_metrics(predictions_threshold, test$has_card)$f1
  
  # Append f1-score to vector
  f1_scores <- c(f1_scores, f1)
}

# Find the index of the maximum f1-score
best_index <- which.max(f1_scores)

# Print the best f1-score and the corresponding number of variables
print(paste("Best f1-score:", f1_scores[best_index]))
print(paste("Number of variables:", best_index))

# Plot the f1-scores
plot(1:length(f1_scores), f1_scores, type = "l", xlab = "Number of variables", ylab = "f1-score")
```

```{r}
set.seed(27)
# Fit a random forest model to the training data
model <- randomForest(has_card ~ ., data = train %>% select(has_card, importance_values$variable[1:7]), method = "class")

# Make predictions on the test data (second column is for probability of true)
predictions <- predict(model, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
get_metrics(predictions_threshold, test$has_card)
```



# Hyperparamter Optimierung auf Random Forest

```{r}
set.seed(27)
# Define the hyperparameter grid
param_grid <- expand.grid(mtry = c(0.1, 1, 10, 100),
                         splitrule = c("gini", "extratrees"),
                         min.node.size = c(1, 10, 15, 20),
                         max.depth = seq(1, 30, 5),
                         ntree = c(100, 500, 1000))

# Define the model using the train() function
model <- randomForest(has_card ~ .,
               data = train %>% select(has_card, importance_values$variable[1:7]),
               method = "rf",
               tuneGrid = param_grid,
               trControl = trainControl(method = "cv", number = 5))

# Make predictions on the test data
predictions <- predict(model, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

print(model)

# Evaluate the model's performance
get_metrics(predictions_threshold, test$has_card)
```



# Recursive Feature Elimnation

Eine Möglichkeit, die Leistung von Random Forest zu verbessern, ist die Verwendung von Recursive Feature Elimination (RFE).

RFE ist ein Feature Selection-Verfahren, das dazu verwendet wird, die wichtigsten Features (also diejenigen Merkmale, die für die Vorhersage am wichtigsten sind) auszuwählen und alle anderen zu entfernen. Dies hat mehrere Vorteile:

Es reduziert die Laufzeit von Random Forest, da weniger Features verarbeitet werden müssen.
Es kann dazu beitragen, Overfitting zu vermeiden, indem es irrelevanten oder redundanten Features entfernt.
Es kann dazu beitragen, die Interpretierbarkeit von Random Forest zu verbessern, da wichtigere Features leichter zu verstehen sind.


```{r}
# Define the control object
control <- rfeControl(functions = rfFuncs,
                      method = "repeatedcv",
                      repeats = 5)

# Perform RFE
model <- rfe(x = train %>% select(-has_card), y = train$has_card,
             sizes = c(1:19, seq(from = 20, to = ncol(train), by = 10)),
             rfeControl = control)

# Extract the selected features
selected_features <- model$optVariables

print(model)

```

```{r}
# Fit a random forest model using the selected features
model <- randomForest(has_card ~ ., data = train[c(selected_features, "has_card")], method = "class")

# Make predictions on the test data
predictions <- predict(model, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
get_metrics(predictions_threshold, test$has_card)
```



