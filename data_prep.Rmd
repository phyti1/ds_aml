---
title: "aml"
subtitle: "Mini-Challenge 1"
author: "Pascal Berger und Raphael Strebel"
date: "18. Oktober 2022"
output:
  html_notebook:
    toc: true
    toc_depth: 4
    df_print: paged
    toc_float:
      collapsed: true
      smooth_scroll: true
    theme: united
    highlight: tango
    code_folding: hide
---
R-Version: **[Default] [64-bit] C:\\Program Files\\R\\R-4.1.0**

# Imports

```{r echo=FALSE, cache=FALSE, results=FALSE, comment=FALSE, warning=FALSE}
# clear environment
rm(list = ls())

# nötige Packete
packages <- c("tidyverse", "data.table", "tidymodels", "lubridate", "caret", "pROC", "randomForest", "rpart", "rpart.plot", "xgboost", "DALEX")

# Noch nicht installierte Pakete installieren
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# Laden der Packete
invisible(lapply(packages, library, character.only = TRUE))

# change options
options(dplyr.summarise.inform = FALSE)

set.seed(27)
```

Die Daten haben wir von folgender Quelle bezogen und werden auch auf dieser genauer Beschrieben: https://sorry.vse.cz/~berka/challenge/PAST/index.html
(linke Seite PKDD'99 Challenge > Data > Financial Data Description)

# Einlesen der Daten

Der Datensatz besteht aus acht verschiedenen Tabellen, welche teils durch Keys miteinander verknüpft sind.

```{r}
root_path <- "./xselling_banking_data-1/xselling_banking_data/"

accounts <- read.csv(paste0(root_path, "account.csv"), header = TRUE, sep = ";")
cards <- read.csv(paste0(root_path, "card.csv"), header = TRUE, sep = ";")
clients <- read.csv(paste0(root_path, "client.csv"), header = TRUE, sep = ";")
dispositions <- read.csv(paste0(root_path, "disp.csv"), header = TRUE, sep = ";")
districts <- read.csv(paste0(root_path, "district.csv"), sep = ";")
loans <- read.csv(paste0(root_path, "loan.csv"), header = TRUE, sep = ";")
orders <- read.csv(paste0(root_path, "order.csv"), header = TRUE, sep = ";")
transactions <- read.csv(paste0(root_path, "trans.csv"), header = TRUE, sep = ";")
```

# Cleaning

## Accounts
```{r}
sample_n(accounts, 5)
```
Die Account-Tabelle enthält vier Kolonnen: die Account-ID, die District-ID (welche auf die District-Tabelle verweist), die Frequenz, welche die Häufigkeit der Ausstellung der Abrechnungen als Kategorie besagt, und das Erstellungsdatum des Accounts. Die Frequenz kann eine von drei verschiedenen Werten annehmen.

```{r}
unique(accounts$frequency)
```

Nachfolgend sollen die Frequenz-Werte übersetzt und das Datum in ein richtiges Format transformiert werden. Ausserdem soll die Tabelle auf fehlende Werte überprüft werden.

```{r}
accounts$date <- as.Date(as.character(accounts$date), format= "%y%m%d")

accounts$frequency[accounts$frequency == "POPLATEK MESICNE"]   <- "monthly"
accounts$frequency[accounts$frequency == "POPLATEK TYDNE"]     <- "weekly"
accounts$frequency[accounts$frequency == "POPLATEK PO OBRATU"] <- "after_transaction"

sum(is.na(accounts))
```

Es gibt also keine fehlende Werte in diesem Dataframe.

## Cards

```{r}
sample_n(cards, 5)
```
Die Card-Tabelle enthält die Kolonnen Card-ID, Disp-ID (welche auf die Dispositon-Tabelle verweist), den Typ der Karte und das Ausstellungsdatum. Auch hier muss das Datum umgewandelt werden. Der zeitliche Teil wird ignoriert, da er immer 0 ist. Weiter werden Gold-Karten zu normalen Karten umgewandelt und Junior-Karten entfernt, da unser Modell das Kaufen einer normalen Karte vorhersagen soll. Auch hier werden wieder die fehlenden Werte geprüft.

```{r}
cards$issued <- as.Date(as.character(cards$issued), format= "%y%m%d")

cards$type[cards$type == "gold"]     <- "classic"
cards <- filter(cards, type == "classic")

sum(is.na(cards))
```

Es gibt keine fehlende Werte, welche weitere Aktionen erfordern würden.

## Clients

```{r}
sample_n(clients, 10)
```

Die Tabelle Clients enthält die Client-ID, das Geburtsdatum und die District-ID (welche auf die District-Tabelle verweist). Der Spalte Geburtsdatum sieht man auf den ersten Blick die Datumsräpresentation nicht an. In der Doku wird aber die Struktur ersichtlich: Das Datumsformat ist für Männer YYMMDD und für Frauen YYMMDD+50DD.

In Folge wird die Nummer in ihre Datumsräpresentation konvertiert und die Spalte "gender" als male/female aufgeschlüsselt. Zudem wird das Alter der Kunden im Jahr 1999 berechnet, da der Datensatz aus diesem Jahr stammt. Anschliessend kann das Geburtsdatum entfernt werden.

Ausserdem werden auch hier wieder die fehlenden Werte überprüft.

```{r}
# Months above 12 must be female
clients <- mutate(clients, gender = 
                     ifelse(substr(birth_number, 3, 4) > 12, "female", "male"))

# Substract the 50 to get the birth month
clients <- mutate(clients, birth_month =
                     ifelse(as.numeric(substr(birth_number, 3, 4)) > 12,
                            as.numeric(substr(birth_number, 3, 4)) - 50,
                            as.numeric(substr(birth_number, 3, 4))))

# Transform the birth_number to a date
clients <- mutate(clients, birth_number = paste("19",
                                                substr(birth_number, 1, 2), 
                                                str_pad(birth_month, 2,
                                                        pad = "0"),
                                                substr(birth_number, 5, 6),
                   sep = "", collapse = NULL))
clients$birth_date <- as.Date(as.character(clients$birth_number),
                               format= "%Y%m%d")

# Remove unused columns
clients$birth_month <- NULL
clients$birth_number <- NULL

# Get the age of the clients in the year 1999 and save it in a column
get_age <- function(birth_date) {
  base_year <- 99
  year <- substr(birth_date, 3, 4)
  result <- base_year - as.integer(year)
  
  return(result)
}
clients <- clients %>%
   mutate(age = get_age(birth_date))

clients$birth_date <- NULL

sum(is.na(clients))
```
Auch hier gibt es keine fehlenden Werte, welche untersucht werden müssten.

Jugendliche und Personen, welche während des Zeitraums des Datensatzes erst erwachsen worden sind, sollen nicht in die Auswertung einfliessen.
Da sich der Datensatz über einen Zeitraum von sechs Jahren erstreckt werden alle Clients jünger als 25 Jahre herausgefiltert.

```{r}
clients <- clients %>% filter(age >= 25)
```

## Dispositions

```{r}
sample_n(dispositions, 5)
```
Die Tabelle Dispostions enthält die Disposition-ID, die Client-ID (welche auf die Tabelle Clients verweist), die Account-ID (welche auf die Tabelle Accounts verweist) und den Typ der Disposition. Disposition steht dabei für die Rechte eines Kunden für ein gewisses Konto. Hier sollen nur Owners verwendet werden, da die Analyse nur Eigentümer von Konten behandeln soll. Da der Type dann für jede Dispostion der gleiche ist, kann diese Variabel entfernt werden.

```{r}
dispositions <- dispositions %>% filter(type == 'OWNER')
dispositions$type <- NULL

sum(is.na(dispositions))
```

Auch hier gibt es keine fehlenden Werte, welche genauer untersucht werden müssten.

## Districts

```{r}
sample_n(districts, 5)
```
Die Tabelle Districts enthält demographische Informationen über verschiedene Gebiete. Die Spaltennamen sind hier nur nummeriert und müssen richtig benannt werden. Dies können wir anhand der Doku machen.

```{r}
districts <- rename(districts, district_id = A1, district_name = A2, region = A3, 
                   inhabitants = A4, municipalities_inhabitants_smaller_499 = A5, 
                   municipalities_inhabitants_500_to_1999 = A6, 
                   municipalities_inhabitants_2000_to_9999 = A7, 
                   municipalities_inhabitants_larger_10000 = A8, cities = A9, 
                   urban_inhabitants_ratio = A10, average_salary = A11,
                   unemployment_rate_95 = A12, unemployment_rate_96 = A13,
                   entrepreneurs_per_1000 = A14, crimes_95 = A15,
                   crimes_96 = A16)

sum(is.na(districts))
```
Auch hier gibt es keine fehlenden Werte.

## Transactions

```{r}
sample_n(transactions, 5)
```

Die Transaktions-Tabelle enthält die Kolonnen Transaktions-ID, Account-ID (welche auf die Tabelle Accounts verweist), Date (das Datum der Transaktion), Type (den Typ der Transaktion), Operation und k_symbol (weitere kategorische Informationen über die Transaktion), Amount (der absolute Wert der Transaktion), Balance (der neue Kontostand) und Informationen über die Bank und den Account.

In den Transaktionen muss das Datum gemäss Format YYMMDD konvertiert und die verschiedenen tschechischen Ausdrücke übersetzt werden. "VYDAJ" heisst übersetzt Ausgabe, "VYBER" Entnahme. Wir übersetzen hier beide Begriffe mit dem Wert "withdrawal".

```{r}
# Change formats
transactions$date <- as.Date(as.character(transactions$date), format= "%y%m%d")
transactions$amount <- as.numeric(transactions$amount)
transactions$balance <- as.numeric(transactions$balance)

# Translate values
transactions$type[transactions$type == "PRIJEM"] <- "income"
transactions$type[transactions$type == "VYDAJ"]  <- "withdrawal"
transactions$type[transactions$type == "VYBER"]  <- "withdrawal"

transactions$operation[transactions$operation == "VKLAD"]          <- "cash credit"
transactions$operation[transactions$operation == "PREVOD Z UCTU"]  <- "collection"
transactions$operation[transactions$operation == "VYBER"]          <- "cash withdrawal"
transactions$operation[transactions$operation == "PREVOD NA UCET"] <- "remittance"
transactions$operation[transactions$operation == "VYBER KARTOU"]   <- "card withdrawal"

transactions$k_symbol[transactions$k_symbol == "DUCHOD"] <- "pension"
transactions$k_symbol[transactions$k_symbol == "UROK"] <- "interest"
transactions$k_symbol[transactions$k_symbol == "SIPO"] <- "household"
transactions$k_symbol[transactions$k_symbol == "SLUZBY"] <- "payment statement"
transactions$k_symbol[transactions$k_symbol == "POJISTNE"] <- "insurance"
transactions$k_symbol[transactions$k_symbol == "SANKC. UROK"]  <- "neg_interest"
transactions$k_symbol[transactions$k_symbol == "UVER"]  <- "loan_pay"

sum(is.na(transactions))
```

In dieser Spalte gibt es eine grosse Anzahl fehlender Werte. Bereits im Sample ist ersichtlich, dass bei den Kolonnen bank, k_symbol und account fehlende Werte als NA oder als leerer string vorkommen. Der Anteil fehlender Werte soll als nächstes untersucht werden.

```{r}
missing_bank_percentage = round(sum(transactions$bank == '') * 100 / dim(transactions)[1], 2)
missing_k_symbol_percentage = round(sum(transactions$k_symbol == '') * 100 / dim(transactions)[1], 2)
missing_account_percentage = round(sum(is.na(transactions$account)) * 100 / dim(transactions)[1], 2)

print(paste("In der Kolonne Bank fehlen", missing_bank_percentage, "% der Werte."))
print(paste("In der Kolonne k_symbol fehlen", missing_k_symbol_percentage, "% der Werte."))
print(paste("In der Kolonne Account fehlen", missing_account_percentage, "% der Werte."))
```

Bei den Kolonnen bank und account fehlen fast drei Viertel der Werte, bei k_symbol beinahe die Hälfte. Daher haben wir uns entschieden, diese Kolonnen vom Dataframe zu entfernen.

```{r}
transactions$bank <- NULL
transactions$k_symbol <- NULL
transactions$account <- NULL
```

Jetzt schauen wir uns nochmals die fehlenden Werte an.

```{r}
sum(is.na(transactions))
```
Durch das Entfernen der drei Spalten konnten alle fehlenden Werte entfernt werden. Nun besteht aber noch das Problem, dass der angegebene Betrag der Transaktionen immer positiv ist, auch wenn das Vermögen sinkt. Wir gehen also davon aus, dass immer der absolute Wert in diesere Kolonne erfasst ist. Dies müssen wir noch bereinigen, so dass der Betrag auch negativ sein kann.

Glücklicherweise gibt es eine weitere Information, welche uns bei diesem Problem weiterhilft: Die Variable "type". 

```{r}
unique(transactions$type)
```

Es gibt nur zwei Transaktionstypen: income und withdrawl. Diese geben an, ob Geld auf das Konto fliesst oder entnommen wird. Bei Transaktionen mit Typ "withdrawal" kann also der Betrag negiert werden. Wir fügen die neuen Variabeln "difference" und "prev_balance" hinzu. Sie beschreiben den Betrag mit entsprechendem Vorzeichen und den Kontostand vor der Transaktion.

```{r}
df <- transactions

# Konvertieren Sie das 'date'-Feld in ein Datum
#df$date <- as.Date(df$date)

# Sortieren Sie das Dataframe nach Nutzer und Datum. Bei gleichem Datum wird nach tranaction_id sortiert. 
df <- df[order(df$account_id, df$date, df$trans_id), ]

# Gruppieren Sie das Dataframe nach Nutzer
df <- group_by(df, account_id)

# Iterieren Sie über jeden Nutzer und bearbeiten Sie die Transaktionen
df <- df %>% 
  summarize(transactions = {
    
    # Die Different der Transaktion zur Vorherigen wird mittels Typ ausgelesen
    difference <- ifelse(type == "withdrawal", amount, amount * -1)
    
    # Balance ist der Kontostand nach der Transaktion, mittels difference wird der Kontostand vor Transaktion ermittelt.
    prev_balance <- balance - difference

    # Erstellen Sie das Dataframe mit den Transaktionen für jeden Nutzer
    transactions_df <- data.frame(amount, date, balance, prev_balance, difference)
    transactions_df
  }) %>%
  ungroup()

transactions <- unnest(df, transactions)

sample_n(transactions, 5)
```

## Orders

Die Tabelle Orders enthält Informationen über einen Zahlungsauftrag. Sie enthällt die Kolonnen Order-ID, Account-ID (welche auf die Tabelle Accounts verweist), Bank-To (welche beschreibt, an welche Bank die Zahlung geht), Account-To (welche auf die Tabelle Accounts verweist und den Empfänger der Zahlung angibt), Amount (den Betrag der Zahlung) und k_symbol (den Typ der Transaktion). Die Werte in der Spalte k_symbol sollen wieder übersetzt werden. Fehlende Werte sollen hier mit "unknown" ersetzt werden.

```{r}
sample_n(orders, 5)
```

```{r}
# Rename column k_symbol
orders <- rename(orders, "characterization" = "k_symbol") 

# Translate column characterization
orders$characterization[orders$characterization == "SIPO"]     <- "household"
orders$characterization[orders$characterization == "UVER"]     <- "loan"
orders$characterization[orders$characterization == "POJISTNE"] <- "insurance"
orders$characterization[orders$characterization == "LEASING"]  <- "leasing"
orders$characterization[orders$characterization == " "]  <- "unknown"
orders$characterization[orders$characterization == ""]  <- "unknown"

orders$amount <- as.numeric(orders$amount)

sum(is.na(orders))
```

Auch hier gibt es keine fehlenden Werte.

## Loans

```{r}
sample_n(loans, 5)
```

Die Tabelle Loans enthält Informationen über Darlehen der verschiedenen Accounts. Dabei stehen uns Informationen wie das Datum, die Höhe, die Dauer, der Betrag der zahlungen und den Status der Darlehen zur Verfügung. Auch hier soll wieder das Datumsformat geändert und der Status der Darlehen in einen besser lesbaren Wert umgewandelt werden. Die Informationen über die verschiedenen Status sind der Dokumentation des Datensatzes zu entnehmen.

```{r}
loans$date <- as.Date(as.character(loans$date), format= "%y%m%d")
loans$payments <- as.numeric(loans$payments)
loans$amount <- as.numeric(loans$amount)

# Make column status human readable
loans$status[loans$status == "A"] <- "finished_payed"
loans$status[loans$status == "B"] <- "finished_not_payed"
loans$status[loans$status == "C"] <- "running_ok"
loans$status[loans$status == "D"] <- "running_in_debt"

sum(is.na(loans))
```

Auch hier gibt es keine fehlenden Werte.

# Zusammenfügen der Dataframes

Als nächstes fassen wir die Dataframes zu einem grossen Dataframe zusammen, damit wir später Modelle darauf trainieren können. Dabei müssen wir überprüfen, ob es sich bei den Verbindungen der verschiedenen Tabellen um n zu n Beziehungen handelt. Wir starten mit der Tabelle Clients und fügen immer mehr Tabellen hinzu.

## Clients und Dispositions

```{r}
print(paste("Anzahl Kunden in Clients:", dim(clients)[1]))
print(paste("Anzahl Dispositions:", dim(dispositions)[1]))
```
Es gibt also weniger Dispositions als Clients. Aber gibt es Clients mit mehreren Dispositions?

```{r}
length(unique(dispositions$client_id))
```

Nein, es gibt keine Clients mit mehreren Dispositionen. Wir können also die beiden Dataframes anhand eines Inner-Joins miteinander verbinden, verlieren dabei aber mehr als 600 Kunden. Diese Kunden sind für uns sowieso irrelevant, da sie keine Konten besitzen.

```{r}
full <- inner_join(clients, dispositions, by = "client_id", suffix = c(".client", ".dispositions"))
print(paste("Anzahl Kunden mit Dispositionen:", dim(full)[1]))
```
Es bleiben also 3858 Kunden.

## Accounts

```{r}
print(paste("Anzahl Accounts:", dim(accounts)[1]))
```

Es gibt also gleich viele Accounts wie Dispositionen. Auch hier soll wieder überprüft werden, ob jeder Account genau einen Owner hat.

```{r}
# Count the number of dispositions per client
acc_counts <- count(accounts, "client_id")

# Create a summary of the counts
summary <- table(acc_counts$n)

summary
```
Jeder Account hat genau einen Owner. Das Dataframe Accounts kann also zu unserem grossen Dataframe hinzugefügt werden.

```{r}
full <- inner_join(full, accounts, by = "account_id", suffix = c("", ".accounts"))
dim(full)[1]
```
Unser Dataframe hat immer noch eine Länge von 4500.

## Loans

```{r}
print(paste("Anzahl Loans:", dim(loans)[1]))
```
Es gibt nur 682 Loans. Das bedeutet, dass nicht jeder Kunde ein Darlehen hat, was Sinn ergibt. Weiter soll noch überprüft werden, ob es Kunden gibt, welche mehrere Darlehen haben.

```{r}
length(unique(loans$account_id))
```

Es gibt also keine Kunden, welche mehrere Darlehen bezogen haben. Die Loans sollen an das gesamte Dataframe mittels Left Join agehängt werden. So gibt es Kunden, welche keine Loans haben und die Variabeln den Wert NA haben. Bei diesen sollen die fehlenden numerischen Werte durch 0 ersetzt und der Status auf "no_loan" geändert werden. Das Datum des Loans entfernen wir.

```{r}
full <- left_join(full, loans, by = "account_id", suffix = c("", ".loans"))
full$amount <- ifelse(is.na(full$amount), 0, full$amount)
full$duration <- ifelse(is.na(full$duration), 0, full$duration)
full$payments <- ifelse(is.na(full$payments), 0, full$payments)
full$status <- ifelse(is.na(full$status), "no_loan", full$status)
full$date.loans <- NULL
```

## Cards

```{r}
print(paste("Anzahl Cards:", dim(cards)[1]))
```
```{r}
length(unique(cards$disp_id))
```

Es gibt 747 Kunden mit Karten, kein Kunde hat mehrere Karten. Es macht wieder Sinn, dass nicht alle Kunden eine Karte habe. Der Typ der Karte ist immer gleich. Daher wird der Typ der Karte durch einen boolischen Wert "has_card" ersetzt. Dies wird auch unsere Zielvariabel in den Modellen sein. Auch die Card-ID kann entfernt werden.

```{r}
full <- left_join(full, cards, by = "disp_id", suffix = c("", ".cards"))
```

```{r}
has_card_function <- function(x) {
  if (is.na(x)) {
    return(FALSE)
  } else {
    return(TRUE)
  }
}

full$has_card <- sapply(full[, "card_id"], has_card_function)
full <- full %>% select(-card_id, -type)
```

## Orders

```{r}
print(paste("Anzahl Orders:", dim(orders)[1]))
```

```{r}
length(unique(orders$account_id))
```
Es gibt 6471 Orders für 3758 Kunden. Das bedeutet, dass es Kunden gibt, welche mehrere Orders haben. Diese Informationen müssen wir zu einer Row zusammenfassen. 

Dabei haben wir uns dafür entschieden, die Variabeln account_to und amount nicht in den Gesamtdatensatz einfliessen zu lassen. Der amount ist bereits in den Transaktionen inbegriffen. An wen die Zahlungen gehen sollten keinen Einfluss auf unser Modell haben.

Also bleiben uns noch die Variabeln characterization und bank_to. Zuerst schauen wir uns an, wie viele verschiedene Werte diese beiden Variabeln annehmen können.

```{r}
unique(orders$characterization)
length(unique(orders$characterization))
```
```{r}
unique(orders$bank_to)
length(unique(orders$bank_to))
```

Bei diesen beiden Variabeln gibt es nur 5 bzw. 13 verschiedene Ausprägungen. Wir können also diese Werte wie folgt an den grossen Datensatz anfügen:

Für jede Ausprägung der Spalte gibt es eine neue Kolonne. Diese Kolonne nimmt den Wert der Anzahl der Orders mit dieser characterization bzw. bank_to an.

```{r}
characterizations <- orders %>%
  group_by(account_id, characterization) %>%
  count()

characterizations_wide <- characterizations %>%
  spread(key = characterization, value = n)

bank_tos <- orders %>%
  group_by(account_id, bank_to) %>%
  count()

bank_tos_wide <- bank_tos %>%
  spread(key = bank_to, value = n)

orders <- merge(characterizations_wide, bank_tos_wide, by = "account_id")

orders[is.na(orders)] <- 0
```

```{r}
full <- left_join(full, orders, by = "account_id")
```

Die fehlenden Werte in diesen Kolonnen müssen jetzt noch mit 0 ersetzt werden. Der Einfachheit halber setzen wir diese Werte hardcoded.

```{r}
full$household[is.na(full$household)] <- 0
full$insurance[is.na(full$insurance)] <- 0
full$leasing[is.na(full$leasing)] <- 0
full$loan[is.na(full$loan)] <- 0
full$unknown[is.na(full$unknown)] <- 0
full$AB[is.na(full$AB)] <- 0
full$CD[is.na(full$CD)] <- 0
full$EF[is.na(full$EF)] <- 0
full$GH[is.na(full$GH)] <- 0
full$IJ[is.na(full$IJ)] <- 0
full$KL[is.na(full$KL)] <- 0
full$MN[is.na(full$MN)] <- 0
full$OP[is.na(full$OP)] <- 0
full$QR[is.na(full$QR)] <- 0
full$ST[is.na(full$ST)] <- 0
full$UV[is.na(full$UV)] <- 0
full$WX[is.na(full$WX)] <- 0
full$YZ[is.na(full$YZ)] <- 0
```

## Districts

Jeder Kunde sowie jeder Account ist einem Gebiet zugewiesen. Zuerst überprüfen wir, ob es sich dabei immer um das selbe Gebiet handelt.

```{r}
sum(full$district_id != full$district_id.accounts)
```
409 Personen haben ihren Account also in einem anderen Distrikt, als sie zugewiesen sind. Wir müssen also die District-Informationen für beide District-ID's zuweisen. Dies machen wir wieder mit Left-Joins.

```{r}
full <- left_join(full, districts, by = "district_id")

full <- left_join(full, districts, by = c("district_id.accounts"="district_id"), suffix = c("", ".accounts"))
```

Zum Schluss können die verschiedenen ID's entfernt werden, da sie irrelevant für das Modell sind und nicht mehr gebraucht werden. Einzig die Account-ID wird im Datensatz behalten, damit die Transaktionen hinzugefügt werden können.

```{r}
full <- full %>% select(-client_id, -district_id, -disp_id, -district_id.accounts, -loan_id)
```

Unser zusammengesetztes Dataframe sieht nun wie folgt aus:

```{r}
full
```

Er beinhaltet 3858 Kunden mit 59 verschiedenen Merkmalen.

## Transactions

Nun müssen nur noch die Transaktionsdaten zum Dataframe hinzugefügt werden. Diese müssen aber anders zusammengefasst werden, da jeder Kunde viele Transaktionen haben kann. Die Transaktionen werden für Kreditkartenkäufer und Nicht-Käufer aggregiert, weshalb wir diese als ersten anhand der Variable "has_card" trennen.

```{r}
card_buyers <- full %>% filter(has_card == TRUE)
non_buyers <- full %>% filter(has_card == FALSE)

print(paste("Anzahl Käufer:", dim(card_buyers)[1]))
print(paste("Anzahl Nicht-Käufer:", dim(non_buyers)[1]))
```
Es gibt 706 Kreditkartenkäufer und 3152 Nicht-Käufer.

### Aggregation der Transaktionen für Kreditkartenkäufer

Bei den Kreditkartenkäufern ist der Zeitpunkt des Kreditkartenkaufs gegeben. Da unser Modell Vorhersagen soll, ob ein Kunde eine Kredikarte kauft, haben die Monate unmittelbar vor dem Kaufzeitpunkt den grössten Einfluss. Wir erstellen also für jeden Kreditkartenkäufer ein Rollup-Fenster für die letzten zwölf Monate vor dem Kauf der Kreditkare, minus einem Monat Lag. Diesen Monat beachten wir nicht, da die Bearbeitung eines Kreditkartenkaufs etwa diese Zeitspanne dauert und sich der Kunde dementsprechend bereits vor dem Kaufdatum für eine Kreditkarte interessiert hat.

Als Erstes werden dafür die Transaktionen von Kunden herausgefiltert, welche eine Kreditkarte haben.

```{r}
account_ids <- card_buyers$account_id
buyer_transactions <- transactions[transactions$account_id %in% account_ids,]
```

Das Kreditkartenkaufdatum soll zu den Transaktionen hinzugefügt werden, damit diese für jeden Kunden einzeln gefiltert werden können.

```{r}
buyer_transactions <- merge(buyer_transactions, full[, c("account_id", "issued")], by="account_id")
```

Nun sollen Transaktionen so gefiltert werden, dass nur noch Transaktionen zwischen 13 Monaten und 1 Monat vor dem Anfang des Monats des Kreditkartenkaufes vorkommen.

```{r}
filter_time_range <- function(df)
{
  filtered_df <- df %>%
    filter(date >= floor_date(issued %m-% months(13), "month") &
         date <= (floor_date(issued %m-% months(1), "month") - days(1)))
  return(filtered_df)
}

filtered_df <- filter_time_range(buyer_transactions)
```

Es existieren oft Monate, bei denen ein Kunde keine Transaktionen gemacht hat. Dies liegt entweder daran, dass der Kunde nicht viele Transaktionen tätigt oder die Kreditkarte bereits im ersten Jahr gekauft hat. In diesen Monaten werden in Folge jeweils eine leere Transaktion eingefügt, welche die Balance der letzten Transaktion des Vormonats trägt. 

```{r}
impute_missing_months <- function(filtered_df)
{
  filtered_df$month <- format(filtered_df$date, "%Y-%m")
  rows_to_impute <- filtered_df %>% group_by(account_id) %>% filter(n_distinct(month) != 12)
  rows_to_impute <- rows_to_impute[order(rows_to_impute$account_id, rows_to_impute$date), ]
  account_ids <- unique(rows_to_impute$account_id)
  print(paste(length(account_ids), "unvollständige Accounts gefunden."))
  pb <- txtProgressBar(min = 0, max = length(account_ids), style = 3, width = 50, char = "=")
  
  for (i in 1:length(account_ids))
  {
    user_transactions <- rows_to_impute[rows_to_impute$account_id == account_ids[i],]
    
    # get all months the client should have a transaction in
    months_target <- sapply(13:2, function(x) format(user_transactions$issued[1] %m-% months(x), "%Y-%m"))
    
    # create dummy transaction in case first month is empty
    new_transaction <- user_transactions[1,]
    new_transaction$difference = 0
    
    # use prev_balance in case the first element gets imputed
    new_transaction$balance <- new_transaction$prev_balance
    
    for (month_target in months_target)
    {
      new_transaction$date <- as.Date(paste0(month_target, "-01"))
      new_transaction$month <- month_target
      # get last transaction of current month from the current user's transactions
      last_transaction <- tail(user_transactions %>% filter(month == month_target), n=1)
      
      if(nrow(last_transaction) == 0)
      {
        # impute empty transaction in missing month
        filtered_df <- rbind(filtered_df, new_transaction)
      }
      else
      {
        new_transaction$balance <- last_transaction$balance
        new_transaction$prev_balance <- new_transaction$balance
      }
    }
    setTxtProgressBar(pb, i)
  }
  close(pb)
  return(filtered_df)
}

filtered_df <- impute_missing_months(filtered_df)
```

Bei 169 Kreditkartenkäufer ist kein komplettes 12-Monats-Rollup-Fenster vorhanden. Bei allen wurden die fehlenden Monate imputiert.

Nun werden diese Daten aggregiert. Es wird eine Gruppierung anhand der account_id und des Monats gemacht. Die Werte "difference" und "balance" auf verschiedene Arten aggregiert:
Auf beiden Werten erfassen wir das Minimum, das Maximum, den Durchschnitt, den Median und die Standardabweichung. Bei "balance" erfassen wir den ersten und den letzten Wert des Monats und bei "difference" die Anzahl positive und negative Differenzen.

```{r}
get_summary_df <- function(filtered_df)
{
  summary_df <- filtered_df %>%
  group_by(account_id, month) %>%
  summarise(
    max_difference = max(difference),
    min_difference = min(difference),
    max_balance = max(balance),
    min_balance = min(balance),
    initial_balance = first(balance),
    end_balance = last(balance),
    mean_balance = mean(balance),
    median_balance = median(balance),
    std_balance = sd(balance),
    mean_difference = mean(difference),
    median_difference = median(difference),
    std_difference = sd(difference),
    count_positive_difference = sum(difference > 0),
    count_negative_difference = sum(difference < 0)
  )
  summary_df <- summary_df %>% arrange(account_id)
  return(summary_df)
}

summary_df <- get_summary_df(filtered_df)
```

Diese Zusammenfassung sieht nun für jeden Kunden folgendermassen aus:

```{r}
summary_df %>% filter(account_id == 7)
```

Für jeden Kunden gibt es nun für jeden Monat vor dem Kreditkartenkauf eine Row mit den aggregierten Daten des Monats. Wir überprüfen noch kurz, ob auch wirklich für jeden Kunden zwölf Monate vorhanden sind.

```{r}
get_incomplete_buyers <- function(summary_df)
{
  # Kontrolle, ob für jeden account_id 12 monate vorhanden sind
  month_counts <- summary_df %>%
      group_by(account_id) %>%
  summarise(month_count = n_distinct(month))

  # Prüfe, ob jedes account_id 12 Monate hat
  month_counts <- month_counts %>% filter(month_count != 12)
  return(month_counts)
}

month_counts <- get_incomplete_buyers(summary_df)
print(paste("Anzahl Kunden mit weniger als 12 Monaten:", dim(month_counts)[1]))
```

Jeder Kreditkartenkäufer hat also wirklich 12 Monate. Als nächstes wollen wir diese zwölf Rows pro Kunde zu einer Row umwandeln. Dafür nummerieren wir zunächst die Monate pro Kreditkartenkäufer von 1 bis 12 durch. Dabei ist der Monat 12 der letzte Monat vor dem Kaufdatum (abgesehen vom Lag-Monat).

```{r}
set_month_ids <- function(summary_df)
{
  # Sortieren nach account_id und Monat
  summary_df <- summary_df[order(summary_df$account_id, rev(summary_df$month)),]
  
  # Hinzufügen der Monatsnummer
  summary_df$group_id <- ave(seq_along(summary_df$account_id), summary_df$account_id, FUN = function(x) {x})
  summary_df$month_number <- 12
  
  for (i in 2:nrow(summary_df)) {
    if (summary_df$account_id[i] != summary_df$account_id[i-1]) {
      summary_df$month_number[i] <- 12
    } else {
      summary_df$month_number[i] <- summary_df$month_number[i-1] - 1
    }
  }
  
  # Entferne die Spalte group_id
  summary_df$group_id <- NULL
  summary_df$month <- NULL
  return(summary_df)
}

summary_df <- set_month_ids(summary_df)

```

Als nächstes brauchen wir pivot_wider. So haben wir jede Kennzahl zwölf mal als Kolonne, jedes Mal mit der vorher erstellten Monatsnummer als Suffix.

```{r}
pivot_by_month <- function(summary_df)
{
  summary_df_wide <- summary_df %>%
    group_by(account_id) %>%
    pivot_wider(names_from = month_number,
              values_from = c(max_difference, min_difference, max_balance, min_balance, initial_balance, end_balance, mean_balance, median_balance, std_balance, median_balance, std_balance, mean_difference, median_difference, std_difference, count_positive_difference, count_negative_difference))
  return(summary_df_wide)
}

summary_df_wide <- pivot_by_month(summary_df)
```

Das daraus resultierende Dataframe sieht so aus:

```{r}
summary_df_wide
```

Für jeden Kreditkartenkäufer gibt es jetzt eine Row mit 169 verschiedenen Merkmalen: Die account_id und die 14 aggregierten Informationen über die Transaktiionen für alle 12 Monate.

Dieses Dataframe fügen wir noch zu den anderen Informationen der Kreditkartenkäufer hinzu.

```{r}
summary_df_buyers <- merge(summary_df_wide, subset(card_buyers), by = "account_id")
```

### Aggregation der Transaktionen für Nicht-Käufer

Für Nicht-Käufer ist kein Datum des Kreditkartenkaufs gegeben, da sie ja keine gekauft haben. Es stellt sich also die Frage, von welchem Datum aus man das Rollup-Fenster erstellt.

Wir haben uns dazu entschieden, für jeden Käufer einen möglichst ähnlichen Nicht-Käufer zu finden. Dafür werden Nichtkäufer mit gleichem Geschlecht und gleicher Region gesucht. Das Kaufdatum des ähnlichen Käufers wird dann auf den Nicht-Käufer übertragen. Ein weiteres Kriterium ist, dass der Nicht-Käufer mindestens eine Transaktion in dem Rollup-Fenster haben muss. Jeder Nicht-Käufer wird maximal einmal als Match genommen, damit keine doppelten Kunden im Datensatz vorkommen.

Durch dieses Vorgehen benutzen wir nur einen Teil der Nicht-Käufer, haben aber direkte, ähnliche Vergleichspersonen, welche im gleichen Zeitraum keine Kreditkarten gekauft haben. Ausserdem bringt das Vorgehen auch den Vorteil, dass die Daten für das Modell automatisch Balanced sind. Dies macht das Trainieren des Modells einfacher, da es dazu beiträgt, dass das Modell nicht Biased gegenüber den Nicht-Käufern wird.


```{r}
pb <- txtProgressBar(min = 0, max = nrow(card_buyers), style = 3, width = 50, char = "=")

# Erstelle ein leeres DataFrame "similar_non_buyers"
similar_non_buyers <- data.frame()

# Iteriere über jeden Kunden im DataFrame "buyers"
for (i in 1:nrow(card_buyers)) 
{
  # Wähle den aktuellen Kunden aus dem DataFrame "buyers"
  current_buyer <- card_buyers[i, ]
  
  similar_non_buyers_temp <- non_buyers %>% filter(gender == current_buyer$gender & 
                                                   region == current_buyer$region)
  
  # damit nicht der gleiche non_buyer doppelt verwendet wird
  similar_non_buyers_temp <- similar_non_buyers_temp[!similar_non_buyers_temp$account_id %in% similar_non_buyers$account_id,]
  
  # filtere non-buyers heraus, welche keine Transaktionen im relevanten Zeitraum vor issued haben
  similar_non_buyers_temp$issued <- current_buyer$issued
  non_buyer_transactions <- merge(transactions, similar_non_buyers_temp[, c("account_id", "issued")], by='account_id')
  non_buyer_filtered <- filter_time_range(non_buyer_transactions)
  non_buyer_ids <- unique(non_buyer_filtered$account_id)
  
  similar_non_buyers_temp <- similar_non_buyers_temp[similar_non_buyers_temp$account_id %in% non_buyer_ids,]
           
  if(nrow(similar_non_buyers_temp) > 0)
  {
    # Wähle den am besten passenden Kunden aus "similar_non_buyers_temp" aus
    best_match_index <- which.min(abs(similar_non_buyers_temp$age - current_buyer$age))
    best_match <- similar_non_buyers_temp[best_match_index, ]
    
    similar_non_buyers <- rbind(similar_non_buyers, copy(best_match))
    setTxtProgressBar(pb, i)
  }
  else
  {
    print(paste0(current_buyer$account_id, ": no non-buyer found"))
  }
}

close(pb)
```
```{r}
print(paste("Anzahl Buyers:", length(unique(card_buyers$account_id))))
print(paste("Anzahl gefundene Matches:", length(unique(similar_non_buyers$account_id))))
```


Wie hier sichtbar wird, konnte zu allen Kartenkäufer ein passender Nicht-Käufer gefunden werden. Auf diesen sollen die Transaktionsdaten jetzt gleich wie bei den Kreditkartenkäufern aggregiert werden. Als erstes werden die Transaktionen wieder auf das gegebene Rollup-Fenster gefiltert.

```{r}
# find missings
non_buyer_transactions <- merge(transactions, similar_non_buyers[, c("account_id", "issued")], by='account_id')
filtered_df <- filter_time_range(non_buyer_transactions)
```

Als nächstes werden wieder Aggregationen für jeden Monat erstellt und fehlende Monate analog zu den Kreditkartenkäufern imputiert.

```{r}
filtered_df <- impute_missing_months(filtered_df)

summary_df_non_buyers <- get_summary_df(filtered_df)
```

Auch hier haben 168 Kunden kein vollständiges Rollup-Fenster. Wir überprüfen wieder, ob für jeden Kunden alle 12 Monate vorhanden sind.

```{r}
month_counts <- get_incomplete_buyers(summary_df_non_buyers)
print(paste("Anzahl Kunden mit weniger als 12 Monaten:", dim(month_counts)[1]))
```

Die Imputation hat funktioniert, es gibt keine Kunden mit weniger als 12 Monaten. Nun werden die Daten wieder auf eine Row ausgeweitet und mit den anderen Informationen der Kunden zusammengefügt.


```{r}
summary_df_non_buyers <- set_month_ids(summary_df_non_buyers)
summary_df_wide <- pivot_by_month(summary_df_non_buyers)
summary_df_non_buyers <- merge(summary_df_wide, similar_non_buyers, by = "account_id")
```

Zum Schluss werden die Käufer und die Nicht-Käufer in einem Datensatz kombiniert. Die Account-ID kann noch entfernt werden.

```{r}
final_df <- rbind(summary_df_buyers, summary_df_non_buyers)
final_df$account_id <- NULL
```

Ausserdem scheinen einige Variabeln als Faktoren im Datensatz zu sein, welche eigentlich numerisch wären.

```{r}
final_df$unemployment_rate_95 <- as.numeric(final_df$unemployment_rate_95)
final_df$unemployment_rate_95.accounts <- as.numeric(final_df$unemployment_rate_95.accounts)
final_df$crimes_95 <- as.numeric(final_df$crimes_95)
final_df$crimes_95.accounts <- as.numeric(final_df$crimes_95.accounts)
```

Bei den berechneten Standardabweichung kommt es auch zu NA-Werten, da es Monate mit nur einer Transaktion gibt und daraus eine Null-Divison entsteht. Diese fehlenden Werte werden durch 0 ersetzt.

```{r}
std_cols <- colnames(final_df %>% select(starts_with("std")))
final_df[,std_cols] <- final_df[,std_cols] %>% replace(is.na(.), 0)
```

Unser finales Dataframe sieht wie folgt aus:

```{r}
final_df
```

Der Datensatz enthält 1412 Kunden mit 226 verschiedenen Variabeln. Die Hälfte der Kunden sind Kreditkartenkäufer. Die Zielvariabel für spätere Modelle ist "has_card".

# EDA

Nun wollen wir unser Dataframe noch ein wenig genauer unter die Luppe nehmen. 

## Anzahl Kreditkarten-Käufer und Nicht-Käufer

```{r}
ggplot(data = final_df, aes(x = has_card)) +
  geom_bar(aes(y = after_stat(count)), stat = "count", fill = "steelblue") +
  labs(x = "Ist Käufer", y = "Anzahl", title = "Anzahl Kreditkarten-Käufer und Nicht-Käufer")
```

Da wir für jeden Kreditkartenkäufer genau einen Käufer suchen, ist der Datensatz ausgeglichen: Es hat gleiche viele Nicht-Käufer wie Käufer.

## Verteilung der Kaufdaten

```{r}
ggplot(final_df, aes(x = issued, fill = factor(has_card))) +
  geom_density(alpha = 0.5) +
  labs(x = "Kaufdatum", y = "Dichte", fill = "Has Card", title = "Verteilung der Kaufdaten") +
  scale_x_date(limits = range(final_df$issued))
```

Dieses Diagramm zeigt die Verteilung der Kaufdaten der Kunden. Da das Kaufdatum des Nicht-Käufers auf das des Käufers gesetzt wird, sind die Verteilungen der beiden Klassen hier deckungsgleich. In den Anfangsjahren des Datensatzes gibt es noch sehr wenige Kreditkartenkäufe, die Tendenz ist jedoch steigend. Ab 1996 erleben die Kreditkartenkäufe einen steilen Aufschwung, welcher Mitte 1998 zu seinem Höhepunkt kommt. Danach werden wieder weniger Käufe getätigt.

## Entwicklung der Vermögen

Als nächstes wollen wir das Vermögen (balance) der Kunden anschauen. Wir beobachten, ob sich das Vermögen von Kunden und nicht Kunden bezüglich Höhe und Entwicklung unterscheidet.

```{r}
averages_true <- colMeans(final_df[final_df$has_card == TRUE,
                                   c("mean_balance_1", "mean_balance_2", "mean_balance_3",
                                     "mean_balance_4", "mean_balance_5", "mean_balance_6",
                                     "mean_balance_7", "mean_balance_8", "mean_balance_9",
                                     "mean_balance_10", "mean_balance_11", "mean_balance_12")])

averages_false <- colMeans(final_df[final_df$has_card == FALSE,
                                    c("mean_balance_1", "mean_balance_2", "mean_balance_3",
                                      "mean_balance_4", "mean_balance_5", "mean_balance_6",
                                      "mean_balance_7", "mean_balance_8", "mean_balance_9",
                                      "mean_balance_10", "mean_balance_11", "mean_balance_12")])

ggplot() +
  geom_line(aes(x = 1:12, y = averages_true, color = "Käufer")) +
  geom_line(aes(x = 1:12, y = averages_false, color = "Nicht-Käufer")) +
  labs(x = "Monat", y = "Durchschnittliches Vermögen", title = "Vermögensentwicklung") +
  scale_color_manual(name = "Kunden", values = c("Käufer" = "steelblue", "Nicht-Käufer" = "red")) +
  scale_x_continuous(limits = c(1, 12)) +
  scale_y_continuous(limits = c(0, NA)) +
  theme(legend.position = "right")
```

Kreditkartenkäufer haben im Schnitt ein höheres Vermögen als Nicht-Käufer. Das Vermögen aller Kunden steigt tendenziell, wobei das der Käufer steiler als das der Nicht-Käufer steigt. Ab dem siebten Monat scheint aber auch diese Vermögenssteigerung abzuflachen.

## Anzahl Transaktionen

Als nächstes wollen wir untersuchen, ob sich Kreditkartenkäufer und Nicht-Käufer durch die Anzahl getätigter Transaktionen unterscheiden. Dafür schauen wir die durchschnittliche Anzahl Transaktionen für beide Klassen an.

```{r}
avg_sum_negative_true <- mean(rowSums(final_df[final_df$has_card == TRUE, grep("count_negative_difference", colnames(final_df))]))
avg_sum_negative_false <- mean(rowSums(final_df[final_df$has_card == FALSE, grep("count_negative_difference", colnames(final_df))]))

avg_sum_positive_true <- mean(rowSums(final_df[final_df$has_card == TRUE, grep("count_positive_difference", colnames(final_df))]))
avg_sum_positive_false <- mean(rowSums(final_df[final_df$has_card == FALSE, grep("count_positive_difference", colnames(final_df))]))

avg_sum_both_true = avg_sum_negative_true + avg_sum_positive_true
avg_sum_both_false = avg_sum_negative_false + avg_sum_positive_false

ggplot() +
  geom_bar(aes(x = c("Käufer", "Nicht-Käufer"), y = c(avg_sum_both_true, avg_sum_both_false)), stat = "identity", fill = c("steelblue", "red")) +
  labs(x = "", y = "Durchschnittliche Anzahl Transaktionen", title = "Durchschnittliche Anzahl Transaktionen im ganzen Rollup-Fenster")
```

Kreditkartenkäufer haben also im Schnitt mehr Transaktionen getätigt als Nicht-Käufer im Rollup-Fenster. Doch wie Verhält es sich, wenn wir Anzahl positive und Anzahl negative Transaktionen separat betrachten?

```{r}
ggplot() +
  geom_bar(aes(x = c("Käufer Ausgaben", "Nicht-Käufer Ausgaben", "Käufer Einnahmen", "Nicht-Käufer Einnahmen"), y = c(avg_sum_negative_true, avg_sum_negative_false, avg_sum_positive_true, avg_sum_positive_false)), stat = "identity", fill = c("steelblue", "red", "steelblue", "red")) +
  labs(x = "", y = "Durchschnittliche Anzahl Transaktionen", title = "Durchschnittliche Anzahl Transaktionen im ganzen Rollup-Fenster")
```

Beide Klassen haben mehr positive Transaktionen als negative, wobei Käufer bei positiven sowie bei negativen durchschnittlich mehr haben. Bei den Einnahmen ist der Unterschied ein wenig höher als bei den Ausgaben.

## Darlehen

Hier soll untersucht werden, ob Käufer mehr Darlehen bei der Bank aufnehmen als Nicht-Käufer.

```{r}
final_df
```


```{r}
card_buyers_with_loan <- final_df[final_df$has_card & final_df$status != "no_loan",]
non_buyers_with_loan <- final_df[!final_df$has_card & final_df$status != "no_loan",]

card_buyers_with_loan_count <- length(card_buyers_with_loan$has_card)
non_buyers_with_loan_count <- length(non_buyers_with_loan$has_card)

ggplot() +
  geom_bar(aes(x = c("Käufer", "Nicht-Käufer"), y = c(card_buyers_with_loan_count, non_buyers_with_loan_count)), stat = "identity", fill = c("steelblue", "red")) +
  labs(x = "", y = "Anzahl", title = "Anzahl Kunden mit Darlehen")
```

Fast doppelt so viele Käufer wie Nicht-Käufer haben ein Darlehen aufgenommen.

# Modelle

Als nächstes wollen wir Modelle trainieren, welche Anhand der Merkmale der Kunden vorhersagen sollen, ob ein Kunde ein Käufer ist oder nicht. Dieses Modell soll dann gebraucht werden, um zu erkennen, welche bestehenden Kunden ohne Kreditkarte am ehesten eine kaufen würden. 

## Funktionen zur Evaluierung von Modellen

Damit die Evaluierung von Modellen nicht redundanten Code enthält, wird hier versucht, Funktionen zu erstellen, welche bei verschiedenen Modellen gebraucht werden können.

### Train-Test-Split

Als Vorbereitung für die Modelle müssen wir unsere Daten zu Trainings- und Testdaten unterteilen. Dafür erstellen wir eine Funktion, welche auf verschiedenen Varianten des Datensatz gebraucht werden kann.


```{r}
split_data <- function(df, test_size = 0.2) {
  set.seed(27)
  df <- df[order(df$issued, decreasing = FALSE), ]
  
  # Get number of rows in the dataframe
  n_rows <- nrow(df)

# Calculate the number of rows in the test set (20% of the total number of rows)
n_test_rows <- floor(n_rows * 0.2)

df$issued <- NULL

# Create the train and test sets
train <- head(df, n_rows - n_test_rows)
test <- tail(df, n_test_rows)
  

#split <- createDataPartition(df$has_card, p = 1 - test_size, list = FALSE)
 # train <- df[split, ]
  #test <- df[-split, ]

# create cv folds
  train_sets <- c()
  val_sets <- c()

  set.seed(27)
  cv_folds <- vfold_cv(train, v = 10)
  # Iteriere über alle Folds
  for (i in 1:nrow(cv_folds)) 
  {
    # Wähle den aktuellen Trainings- und Validierungsdatensatz aus
    train_set <- cv_folds$splits[[i]] %>% analysis()
    val_set <- cv_folds$splits[[i]] %>% assessment()
  
    # Speichere den aktuellen Trainings- und Validierungsdatensatz in den Listen
    train_sets[[i]] <- train_set
    val_sets[[i]] <- val_set
  }
  
  return(list(train = train, test = test, cv_folds = cv_folds, train_sets = train_sets, val_sets = val_sets))
}
```

### Metriken

Damit wir die verschiedenen Modelle besser evaluieren können, müssen wir die gleichen Kennzahlen und Auswertungen pro Modell machen. Zu diesem Zweck definieren wir einige Funktionen, damit wir weniger redundanten Code haben und unsere Ergebnisse in einem einheitliche, vergleichbaren Format daherkommen. 

Dafür erstellen wir eine Funktion, die die Genauigkeit (Accuracy), Cohen's Kappa, Matthews Korrelation, Präzision (Precision), Erinnerung (Recall) und den F1-Score für eine Reihe von Vorhersagen und deren entsprechenden wahren Werte berechnet.

Was bedeuten diese Kennzahlen genau?

Accuracy (Genauigkeit): Die Accuracy ist der Prozentsatz der Vorhersagen, die mit den tatsächlichen Werten übereinstimmen. Sie wird berechnet als Anzahl der korrekten Vorhersagen geteilt durch die Gesamtzahl der Vorhersagen.

Cohen's Kappa (Cohen's Kappa): Cohen's Kappa ist eine Messgröße für die Qualität von binären Klassifikationen. Es wird verwendet, um die Übereinstimmung zwischen zwei Klassifikatoren zu messen, indem es die Übereinstimmung über der erwarteten Übereinstimmung durch Zufall berechnet. Ein Kappa-Wert von 1 bedeutet perfekte Übereinstimmung, ein Wert von 0 bedeutet keine Übereinstimmung, die besser ist als Zufall, und ein Wert von -1 bedeutet komplett falsche Klassifikationen.

Matthews correlation coefficient (Matthews Korrelation): Der Matthews Korrelation Coefficient (MCC) ist eine Messgröße für die Qualität von binären Klassifikationen. Er reicht von -1 bis 1, wobei ein Wert von 1 perfekte Klassifikation bedeutet, ein Wert von 0 eine Klassifikation, die nicht besser als Zufall ist, und ein Wert von -1 eine komplett falsche Klassifikation bedeutet.

Precision (Präzision): Die Präzision ist der Prozentsatz der Vorhersagen, die tatsächlich korrekt waren, unter der Annahme, dass alle Vorhersagen korrekt sind. Sie wird berechnet als Anzahl der korrekten Vorhersagen für die positive Klasse geteilt durch die Gesamtzahl der Vorhersagen für die positive Klasse.

Recall (Erinnerung): Der Recall ist der Prozentsatz der tatsächlich positiven Werte, die korrekt vorhergesagt wurden. Er wird berechnet als Anzahl der korrekten Vorhersagen für die positive Klasse geteilt durch die Gesamtzahl der tatsächlich positiven Werte.

F1 score (F1-Wert): Der F1-Wert ist ein Maß für die Qualität von binären Klassifikationen, das die Harmoniesche Mischung von Präzision und Recall darstellt. Es wird berechnet als der Harmoniesche Mittelwert von Präzision und Recall. Ein hoher F1-Wert bedeutet, dass sowohl Präzision als auch Recall hoch sind.

```{r}
get_metrics <- function(predictions, true_values, model_name) {
  # Calculate accuracy
  accuracy <- sum(predictions == true_values) / length(predictions)
  
  # Calculate Cohen's kappa
  n <- length(predictions)
  observed_agreement <- sum(predictions == true_values)
  expected_agreement <- sum(predictions == true_values) / n
  kappa <- (observed_agreement - expected_agreement) / (n - expected_agreement)
  
  # Calculate Matthews correlation coefficient
  confusion_matrix <- table(predictions, true_values)
  tp <- confusion_matrix[2,2]
  tn <- confusion_matrix[1,1]
  fp <- confusion_matrix[2,1]
  fn <- confusion_matrix[1,2]
  matthews <- (tp * tn - fp * fn) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
  
  # Calculate precision and recall
  precision <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
  recall <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
  
  # Calculate F1 score
  f1 <- 2 * (precision * recall) / (precision + recall)
  
  # Create a data frame of the metrics
  metrics <- data.frame(model = model_name, accuracy = accuracy, kappa = kappa, matthews = matthews,
                        precision = precision, recall = recall, f1 = f1)
  
  # Return the data frame
  return(metrics)
}
```

### Konfusionsmatrix mit Plot

Diese Funktion erstellt eine Konfusionsmatrix und gibt sie als Plot zurück. 

Eine Konfusionsmatrix ist ein wichtiges Werkzeug zur Evaluation von Klassifikationsmodellen. Sie zeigt an, wie gut das Modell in der Lage ist, die verschiedenen Klassen richtig zu identifizieren. In einer Konfusionsmatrix werden die tatsächlichen und die von dem Modell vorhergesagten Klassen gegenübergestellt. Die Matrix ist in vier Quadranten unterteilt: true positives (TP), true negatives (TN), false positives (FP) und false negatives (FN). TP sind die Fälle, in denen das Modell die Klasse richtig vorhergesagt hat, TN sind die Fälle, in denen das Modell die Klasse richtig vorhergesagt hat und diese Klasse auch tatsächlich vorliegt, FP sind die Fälle, in denen das Modell eine Klasse vorhergesagt hat, die in Wirklichkeit nicht vorliegt, und FN sind die Fälle, in denen das Modell eine Klasse nicht vorhergesagt hat, die in Wirklichkeit vorliegt. Eine Konfusionsmatrix ist hilfreich, um die Genauigkeit, Sensitivität und Spezifität des Modells zu berechnen und um zu sehen, an welchen Stellen das Modell Schwächen hat. Sie kann auch verwendet werden, um die Leistung von verschiedenen Modellen miteinander zu vergleichen.

```{r}
plot_confusion_matrix <- function(predictions, true_values) {
  # Erstelle eine Confusion Matrix als Data Frame
  confusion_matrix_df <- data.frame(predictions, true_values)
  
  # Zähle die Häufigkeiten jeder Kombination von Vorhersage- und True-Werten
  counts_df <- count(confusion_matrix_df, predictions, true_values)
  
  # Erstelle einen ggplot-Plot
  ggplot(data = counts_df, aes(x = predictions, y = true_values)) +
    geom_tile(aes(fill = n)) +
    geom_text(aes(label = n)) +
    scale_fill_gradient(low = "white", high = "darkgreen") +
    labs(x = "Predicted Class", y = "True Class", title = "Confusion Matrix")
}
```

### ROC / AUC

Diese Funktion zeichnet die ROC-Kurve und berechnet die Area und Curve. 

Die ROC-Kurve (Receiver Operating Characteristic curve) ist ein wichtiges Werkzeug zur Bewertung von Klassifikatoren. Sie zeigt die Leistung des Klassifikators bei verschiedenen Schwellenwerten an, die zur Unterscheidung zwischen zwei Klassen verwendet werden. Die ROC-Kurve ist besonders nützlich, wenn die beiden Klassen im Verhältnis unausgeglichen sind, wie es oft der Fall ist, wenn es darum geht, seltene Ereignisse wie Krankheiten oder Betrug zu erkennen.

Die ROC-Kurve ist auf der x-Achse der falsch-positiv-Rate (FPR) und auf der y-Achse der wahr-positiv-Rate (TPR) aufgetragen. Der FPR gibt an, wie viele falsch positive Ergebnisse es gibt, während der TPR angibt, wie viele wahr positive Ergebnisse erzielt werden. Ein perfekter Klassifikator würde eine ROC-Kurve haben, die im oberen linken Bereich beginnt und nach rechts oben verläuft, wobei alle Fälle korrekt klassifiziert werden. Ein zufälliger Klassifikator würde eine diagonal verlaufende ROC-Kurve haben, da die FPR und TPR zufällig verteilt sind.

Die AuC (Area Under the Curve) ist eine Metrik, die aus der ROC-Kurve berechnet wird und die Leistung des Klassifikators zusammenfasst. Sie gibt an, wie gut der Klassifikator im Vergleich zu einem zufälligen Klassifikator ist. Eine AUC von 1 bedeutet, dass das Modell perfekt in der Lage ist, positive und negative Klassen zu unterscheiden, während eine AUC von 0.5 bedeutet, dass das Modell keine bessere Leistung als Zufall erzielt. Die AUC kann Werte zwischen 0 und 1 annehmen. Eine AUC von 0 bedeutet, dass das Modell völlig inkorrekt ist. Im Allgemeinen gilt, je größer die AUC, desto besser ist das Modell im Vergleich zu anderen Modellen.

```{r}
make_roc_plot_and_get_auc <- function(predictions, true_values)
{
  roc_curve <- roc(as.numeric(predictions), as.numeric(true_values) - 1)

  plot(roc_curve, xlab = "False Positive Rate", ylab = "True Positive Rate", main ="ROC Curve")

  auc <- auc(roc_curve)

  return(auc)
}
```

### Threshold Plot

```{r}

find_best_threshold <- function(predictions, actual_values) {
  best_threshold <- 0
  best_f1 <- 0
  thresholds <- seq(0.01, 0.99, 0.01)
  f1_scores <- rep(0, length(thresholds))

  for (i in 1:length(thresholds)) {
    # Set the threshold for the predictions
    predictions_threshold <- ifelse(predictions > thresholds[i], TRUE, FALSE)
  
    if (all(predictions_threshold)) {
      next
    } else if (all(!predictions_threshold)) {
      next
    }
    # Calculate the f1
    f1 <- get_metrics(predictions_threshold, actual_values, "best threshold")$f1
  
    f1_scores[i] <- f1
  
    # Update the best threshold and best f1 if necessary
    if (f1 > best_f1) {
      best_threshold <- thresholds[i]
      best_f1 <- f1
    }
  }

  # Display the best threshold and best recall
  print(paste("Best threshold:", best_threshold))
  print(paste("Best F1:", best_f1))

  plot(thresholds, f1_scores, type = "l", xlab = "Threshold", ylab = "F1 Score", main = "F1 Score with different thresholds")

  return(best_threshold)
}
```



## Vorgehen

Um ein geeignets Modell zu finden, werden wir verschiedene Modell-Alogirthmen auf den Trainingsdaten anzuwenden und versuchen, diese zu optimieren. Wir starten dabei mit einem vorgegebenen Baseline Modell. Jedes Modell schauen wir kurz individuell an. Am Schluss werden die verschiedenen Modelle nochmals gesamthaft miteinander verglichen. Dabei schauen wir verschiedene Metriken, Top-N-Listen, Feature-Importance und weitere Informationen wie die ROC-Kurve oder Konfusionsmatrizen. Diese Informationen erhalten wir über 10-fache-Kreuzvalidierung. Wir trainieren also jedes Modell 10 Mal mit verschiedenen 90% der Trainingsdaten und berechnen unsere Metriken und weiteren Informationen auf den restlichen 10%.

Doch welche Metrik in unserer Liste ist die relevanteste für uns? Beim Modell geht es darum, Kunden zu finden, welche am ehesten eine Kreditkarte kaufen würden. Diesen Kunden würden dann für die Bank interessant werden und eine gewisse Massnahme würde ergriffen werden, sei es das Schicken einer Werbung  oder das Unterbreiten eines Angebots. Da dies mit einem zeitlichen Aufwand verbunden ist und Kunden, welche ein solches Angebot oder eine Werbung bekommen aber kein Interesse haben, eher genervt davon werden würden, sollen die vom Modell als positiv klassifizierten Fälle möglichst tatsächlich positiv sein. Daher schauen wir bei den Modellen vor allem auf die Precision.

### Baseline Modell

Als erstes soll eine logistische Regression mit den Informationen Alter, Geschlecht, Domizilregion, Vermögen (balance-Schnitt über alle Monate) und Umsatz (difference-Schnitt über alle Monate) als Baseline Modell erstellt werden.Dafür müssen wir kurz ein neues Dataframe erstellen.

```{r}
baseline_data <- final_df
baseline_data$mean_balance <- rowMeans(final_df[, c("mean_balance_1", "mean_balance_2", "mean_balance_3", "mean_balance_4", 
                                                "mean_balance_5", "mean_balance_6", "mean_balance_7", "mean_balance_8", 
                                                "mean_balance_9", "mean_balance_10", "mean_balance_11", "mean_balance_12")])
baseline_data$mean_difference <- rowMeans(final_df[, c("mean_difference_1", "mean_difference_2", "mean_difference_3", "mean_difference_4", 
                                                  "mean_difference_5", "mean_difference_6", "mean_difference_7", "mean_difference_8", 
                                                  "mean_difference_9", "mean_difference_10", "mean_difference_11", "mean_difference_12")])
baseline_data <- baseline_data[, c("age", "gender", "region", "has_card", "mean_balance", "mean_difference", "issued")]
baseline_data$has_card <- as.factor(baseline_data$has_card)
```

Darauf wird ein Train-Test-Split mit 80% Trainingsdaten und 20% Testdaten gebraucht.
 
```{r}
splits <- split_data(baseline_data, test_size = 0.2)
train <- splits$train
test <- splits$test
train_sets <- splits$train_sets
val_sets <- splits$val_sets
```

Das Regressionsmodell wird auf den Trainingsdaten trainiert. Wir verwenden die Funktion glm von der Library "stats". Bei jedem Modell müssen die Predictions gemacht und damit die Metriken erstellt werden. Da die logistische Regression eine Zahl zwischen 0 und 1 zurückgibt, müssen wir anhand eines Thresholds die Werte zu TRUE und FALSE umwandeln. Der Threshold gibt an, ab welchem Wert eine Vorhersage als positiv betrachtet wird. Standardmäßig ist der Threshold auf 0.5 gesetzt, was bedeutet, dass alle Kunden mit einem Wert grösser als 0.5 als Kartenkäufer betrachtet werden.Die Werte für jede Validierung werden in einer Liste gespeichert. Als erstes wollen wir uns die durchschnittlichen Metriken anschauen.

```{r}
regression_baseline_metrics <- list()
regression_baseline_predictions <- list()
regression_baseline_predictions_threshold <- list()

for(i in 1:length(val_sets)) {
  
  regression_baseline <- glm(has_card ~ ., data = train_sets[[i]], family = binomial)
  
  regression_baseline_predictions[[i]] <- predict(regression_baseline, val_sets[[i]], type = "response")
  
  threshold <- 0.5
  
  regression_baseline_predictions_threshold[[i]] <- ifelse(regression_baseline_predictions[[i]] > threshold, TRUE, FALSE)

  regression_baseline_metrics[[i]] <- get_metrics(regression_baseline_predictions_threshold[[i]], val_sets[[i]]$has_card, "Logistic Regression Baseline")
  
}

regression_baseline_metrics <- do.call("rbind", regression_baseline_metrics)
metrics_all <- regression_baseline_metrics

colMeans(regression_baseline_metrics %>% select(-model))

#regression_baseline_explainer <- explain(regression_baseline, data = train)
```

Um die Konfusionsmatrix anzuzeigen berechnen wir den Schnitt des Wertes der logistischen Regression für jeden Kunden 

```{r}
#plot_confusion_matrix(regression_baseline_predictions_threshold, test$has_card)
```


```{r}
#make_roc_plot_and_get_auc(regression_baseline_predictions, test$has_card)
```

### Regressionsmodell mit allen Daten

Nun soll dieses Baseline-Modell verbessert werden. Als erstes probieren wir, das gleiche Modell (Logistische Regression) mit mehr Input-Parametern zu trainieren. 

Da die logistische Regression Probleme mit Faktoren hat, welche nur im Trainings- bzw. Testdatensatz vorkommen und auch nicht gut mit NA's umgehen kann, müssen wir zuerst noch einige Anpassungen am Datensatz vornehmen.

Als erstes entfernen wir alle Kolonnen, welche Faktoren sind und mehr als 10 verschiedene Ausprägungen haben.

```{r}
# Ermittle die numerischen Merkmale in den Trainingsdaten
numeric_vars <- sapply(final_df, is.numeric)

# Erstelle ein Subset der Trainingsdaten ohne die numerischen Merkmale
train_no_numeric <- final_df[, !numeric_vars]

# Ermittle die Anzahl der Kategorien für jedes Merkmal
num_categories <- sapply(train_no_numeric, function(x) length(unique(x)))

# Überprüfe, ob ein Merkmal zu viele Kategorien hat
too_many_categories <- num_categories > 10

# Gib die Namen der Merkmale aus, die zu viele Kategorien haben
columns_to_remove <- colnames(train_no_numeric)[too_many_categories]


# Ermittle die Spaltennamen, die behalten werden sollen
keep_columns <- setdiff(colnames(final_df), columns_to_remove)

# Erstelle ein Subset des Dataframes mit den behaltenen Spaltennamen
final_df_simplified <- final_df[, keep_columns]

columns_to_remove
```

Nun muss der Datensatz noch auf NA's überprüft werden.

```{r}
# Count the number of NA values in the data frame
num_na <- sum(is.na(final_df_simplified))

# Print the total number of NA values
print(paste("Total number of NA values:", num_na))

# Create a logical vector indicating whether each element is NA
na_matrix <- is.na(final_df_simplified)

# Sum the number of NA values per row
na_counts <- rowSums(na_matrix)

# Count the rows with NA values
num_na_rows <- sum(na_counts > 0)

# Print the number of rows with NA values
print(paste("Number of rows with NA values:", num_na_rows))

# Sum the number of NA values per column
na_counts_cols <- colSums((na_matrix))

# Count the columns with NA values
num_na_cols <- sum(na_counts_cols > 0)

# Print the number of columns with NA values
print(paste("Number of columns with NA values:", num_na_cols))
```

Fast jede Zeile hat irgendwo ein NA. Es sind auch viele Kolonnen betroffen. Wir können also nicht alle Observationen oder Variabeln mit NA's entfernen, da sonst der Datenverlust sehr gross wäre. Daher imputieren wir die numerischen fehlenden Werte mit dem Median und die fehlenden kategorialen Werte mit dem Wert, welcher am meisten vorkommt.

```{r}
# Impute NA numbers with the median
final_df_simplified <- final_df_simplified %>% 
  mutate_if(is.numeric, list(~ if_else(is.na(.), median(., na.rm = TRUE), as.double(.))))

# Impute NA strings/factors with the most common value
final_df_simplified <- final_df_simplified %>% 
  mutate_if(is.character, list(~ if_else(is.na(.), mode(.), .)))
```

Wir überprüfen nochmals, ob es keine fehlenden Werte mehr gibt.

```{r}
sum(is.na(final_df_simplified))
```

Da das Kaufdatum für den Split benötigt wird aber vorher entfernt wurde, da es mehr als 10 verschiedene Ausprägungen annehmen kann, fügen wir es hier nochmals zum neuen Datensatz hinzu.

```{r}
final_df_simplified$issued <- final_df$issued
```


```{r}
splits <- split_data(final_df_simplified, test_size = 0.2)
train <- splits$train
test <- splits$test
train_sets <- splits$train_sets
val_sets <- splits$val_sets
```

```{r}
regression_all_metrics <- list()
regression_all_predictions <- list()
regression_all_predictions_threshold <- list()

for(i in 1:length(val_sets)) {
  
  regression_all <- glm(has_card ~ ., data = train_sets[[i]], family = binomial)
  
  regression_all_predictions[[i]] <- predict(regression_all, val_sets[[i]], type = "response")
  
  threshold <- 0.5
  
  regression_all_predictions_threshold[[i]] <- ifelse(regression_all_predictions[[i]] > threshold, TRUE, FALSE)

  regression_all_metrics[[i]] <- get_metrics(regression_all_predictions_threshold[[i]], val_sets[[i]]$has_card, "Logistic Regression All")
  
}

regression_all_metrics <- do.call("rbind", regression_all_metrics)
metrics_all <- bind_rows(metrics_all, regression_all_metrics)

colMeans(regression_all_metrics %>% select(-model))
```


```{r}

#regression_all_explainer <- explain(regression_all, data = train)
```


```{r}
#plot_confusion_matrix(regression_all_predictions_threshold, test$has_card)
```

```{r}
#make_roc_plot_and_get_auc(regression_all_predictions, test$has_card)
```


```{r}
#plot_feature_importance(regression_all)
```

### Decision Tree

Für den Decison Tree verwenden wir das Package "rpart".

```{r}
decision_tree_metrics <- list()
decision_tree_predictions <- list()
decision_tree_predictions_threshold <- list()

for(i in 1:length(val_sets)) {
  
  decision_tree <- rpart(has_card ~ ., data = train_sets[[i]], method = "class")
  
  decision_tree_predictions[[i]] <- predict(decision_tree, val_sets[[i]], type = "prob")[, 2]
  
  threshold <- 0.5
  
  decision_tree_predictions_threshold[[i]] <- ifelse(decision_tree_predictions[[i]] > threshold, TRUE, FALSE)

  decision_tree_metrics[[i]] <- get_metrics(decision_tree_predictions_threshold[[i]], val_sets[[i]]$has_card, "Decision Tree")
  
}

decision_tree_metrics <- do.call("rbind", decision_tree_metrics)
metrics_all <- bind_rows(metrics_all, decision_tree_metrics)

colMeans(decision_tree_metrics %>% select(-model))
```

```{r}
#plot_confusion_matrix(decision_tree_predictions_threshold, test$has_card)
#make_roc_plot_and_get_auc(decision_tree_predictions, test$has_card)
#predictions_train <- predict(decision_tree, train, type = "prob")[, 2]
#best_threshold <- find_best_threshold(predictions_train, train$has_card)
#rpart.plot(decision_tree)
```


Die Klassifikation ist um einiges besser auf dem Decision Tree. Es scheint also für unseren Verwendungszweck der bessere Algorithmus zu sein. Wir untersuchen noch Erweiterungen des Decision Trees: der Random Forest.



### Random Forest 

Für den Random Forest brauchen wir das Package "randomForest". Es verwendet Breiman's random forest algorithmus und kann für Klassifikation und Regression verwendet werden.

Beim Random Forest muss unsere Zielvariabel noch in einen Faktor umgewandelt werden, damit die Wahrscheinlichkeiten vorhergesagt werden können.

```{r}
random_forest_metrics <- list()
random_forest_predictions <- list()
random_forest_predictions_threshold <- list()

for(i in 1:length(val_sets)) {
  
  train_sets[[i]]$has_card <- as.factor(train_sets[[i]]$has_card)
  
  random_forest <- randomForest(has_card ~ ., data = train_sets[[i]], method = "class")
  
  random_forest_predictions[[i]] <- predict(random_forest, val_sets[[i]], type = "prob")[, 2]
  
  threshold <- 0.5
  
  random_forest_predictions_threshold[[i]] <- ifelse(random_forest_predictions[[i]] > threshold, TRUE, FALSE)

  random_forest_metrics[[i]] <- get_metrics(random_forest_predictions_threshold[[i]], val_sets[[i]]$has_card, "Random Forest")
  
}

random_forest_metrics <- do.call("rbind", random_forest_metrics)
metrics_all <- bind_rows(metrics_all, random_forest_metrics)

colMeans(random_forest_metrics %>% select(-model))
```
Der Random Forest ist ein wenig besser als der Decision Tree. Als nächstes wollen wir probieren, ob eine Hyperparameteroptimierung unser Resultat noch verbessern kann.


```{r}
#plot_confusion_matrix(random_forest_predictions_threshold, test$has_card)
#make_roc_plot_and_get_auc(random_forest_predictions, test$has_card)
#predictions_train <- predict(random_forest, train, type = "prob")[, 2]
#best_threshold <- find_best_threshold(predictions_train, train$has_card)
```

### XGBoost

Das XGBoost Modell wird mit der Library "xgboost" trainiert. Da es Probleme mit nicht-numerischen Variabeln gab, wurden diese entfernt.


```{r}
xg_boost_metrics <- list()
xg_boost_predictions <- list()
xg_boost_predictions_threshold <- list()

for(i in 1:length(val_sets)) {
  
  train_data <- train_sets[[i]]
  test_data <- val_sets[[i]]
  
  train_data[] <- lapply(train_sets[[i]], as.numeric)
  test_data[] <- lapply(val_sets[[i]], as.numeric)

  
  train_data <- cbind(as.numeric(train_sets[[i]]$has_card), train_data)
  test_data <- cbind(as.numeric(val_sets[[i]]$has_card), test_data)
  
  train_preds <- as.matrix(sapply(train_data[,-1], as.numeric))
  train_labels <- train_data[, 1]
  
  test_preds <- as.matrix(sapply(test_data[,-1], as.numeric))
  test_labels <- test_data[, 1]
  
  param <- list(max_depth = 100, eta = 0.1, nthread = 2)

  # Train the model
  xg_boost <- xgboost(data = train_preds, label = train_labels - 1, nrounds = 100, objective = "binary:logistic", verbose = 0, maximize = "precision", params = param)

  # Make predictions on the test data
  xg_boost_predictions[[i]] <- predict(xg_boost, test_preds) 
  
  threshold <- 0.5
  
  xg_boost_predictions_threshold[[i]] <- ifelse(xg_boost_predictions[[i]] > threshold, TRUE, FALSE)
  
  xg_boost_metrics[[i]] <- get_metrics(xg_boost_predictions_threshold[[i]], val_sets[[i]]$has_card, "XGBoost")
  
}

xg_boost_metrics <- do.call("rbind", xg_boost_metrics)
metrics_all <- bind_rows(metrics_all, xg_boost_metrics)

colMeans(xg_boost_metrics %>% select(-model))
```




```{r}
importance_values <- varImp(random_forest)
importance_values$variable <- rownames(varImp(random_forest)) 
importance_values <- importance_values[order(importance_values$Overall, decreasing = TRUE),]

# Wählen Sie die top 10 Merkmale aus
top_features <- head(importance_values, n = 10)
top_features

```

TODO: CHECK if ifelse is correct

```{r}
# Initialize empty vector to store f1-scores
set.seed(27)
f1_scores <- c()

# Loop through each variable and fit a random forest model
for (i in 1:50) {
  # Select subset of variables
  vars_subset <- importance_values$variable[1:i]
  
  # Fit random forest model
  train_reduced <- train %>% select(has_card, vars_subset)
  model <- randomForest(has_card ~ ., data = train_reduced, method = "class")
  
  # Make predictions on test data
  predictions <- predict(model, test, type = "prob")[, 2]
  
  # Threshold predictions
  threshold <- 0.5
  predictions_threshold <- ifelse(predictions > threshold, TRUE, FALSE)
  
  # Calculate f1-score
  f1 <- get_metrics(predictions_threshold, test$has_card, "random forest test")$f1
  
  # Append f1-score to vector
  f1_scores <- c(f1_scores, f1)
}

# Find the index of the maximum f1-score
best_index <- which.max(f1_scores)

# Print the best f1-score and the corresponding number of variables
print(paste("Best f1-score:", f1_scores[best_index]))
print(paste("Number of variables:", best_index))

# Plot the f1-scores
plot(1:length(f1_scores), f1_scores, type = "l", xlab = "Number of variables", ylab = "f1-score")
```

```{r}
set.seed(27)
# Fit a random forest model to the training data
random_forest_important_features <- randomForest(has_card ~ ., data = train %>% select(has_card, importance_values$variable[1:best_index]), method = "class")

cv_method <- trainControl(method = "cv", number = 10)
#random_forest_important_features <- train(has_card ~ ., data = train, method = random_forest_important_features, trControl = cv_method)

random_forest_important_features_explainer <- explain(random_forest_important_features, data = train)

# Make predictions on the test data (second column is for probability of true)
random_forest_important_features_predictions <- predict(random_forest_important_features, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
random_forest_important_features_threshold <- ifelse(predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
random_forest_important_features_metrics <- get_metrics(random_forest_important_features_threshold, test$has_card, "Random Forest (most Important Features)")
metrics_all <- bind_rows(metrics_all, random_forest_important_features_metrics)
random_forest_important_features_metrics
```



# Hyperparamter Optimierung auf Random Forest

```{r}
set.seed(27)
# Define the hyperparameter grid
param_grid <- expand.grid(mtry = c(0.1, 1, 10, 100),
                         splitrule = c("gini", "extratrees"),
                         min.node.size = c(1, 10, 15, 20),
                         max.depth = seq(1, 30, 5),
                         ntree = c(100, 500, 1000))

# Define the model using the train() function
random_forest_hyperparameter <- randomForest(has_card ~ .,
               data = train %>% select(has_card, importance_values$variable[1:7]),
               method = "rf",
               tuneGrid = param_grid,
               trControl = trainControl(method = "cv", number = 10))

random_forest_hyperparameter_explainer <- explain(random_forest_hyperparameter, data = train)

# Make predictions on the test data
random_forest_hyperparameter_predictions <- predict(random_forest_hyperparameter, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
random_forest_hyperparameter_predictions_threshold <- ifelse(random_forest_hyperparameter_predictions > threshold, TRUE, FALSE)

print(random_forest_hyperparameter)

# Evaluate the model's performance
get_metrics(random_forest_hyperparameter_predictions_threshold, test$has_card, "Random Forest (Hyperparamter Optimization")
```



# Recursive Feature Elimnation

Eine Möglichkeit, die Leistung von Random Forest zu verbessern, ist die Verwendung von Recursive Feature Elimination (RFE).

RFE ist ein Feature Selection-Verfahren, das dazu verwendet wird, die wichtigsten Features (also diejenigen Merkmale, die für die Vorhersage am wichtigsten sind) auszuwählen und alle anderen zu entfernen. Dies hat mehrere Vorteile:

Es reduziert die Laufzeit von Random Forest, da weniger Features verarbeitet werden müssen.
Es kann dazu beitragen, Overfitting zu vermeiden, indem es irrelevanten oder redundanten Features entfernt.
Es kann dazu beitragen, die Interpretierbarkeit von Random Forest zu verbessern, da wichtigere Features leichter zu verstehen sind.


```{r}
if (FALSE) {
# Define the control object
control <- rfeControl(functions = rfFuncs,
                      method = "repeatedcv",
                      repeats = 5)

# Perform RFE
rfe <- rfe(x = train %>% select(-has_card), y = train$has_card,
             sizes = c(1:19, seq(from = 20, to = ncol(train), by = 10)),
             rfeControl = control)

# Extract the selected features
selected_features <- rfe$optVariables

print(rfe)
}
```

```{r}
if (FALSE) {
# Fit a random forest model using the selected features
random_forest_rfe <- randomForest(has_card ~ ., data = train[c(selected_features, "has_card")], method = "class")

cv_method <- trainControl(method = "cv", number = 10)
random_forest_rfe <- train(has_card ~ ., data = train, method = random_forest_rfe, trControl = cv_method)

random_forest_rfe_explainer <- explain(random_forest_rfe, data = train)

# Make predictions on the test data
random_forest_rfe_predictions <- predict(random_forest_rfe, test, type = "prob")[, 2]

# Threshold the predicted probabilities
threshold <- 0.5
random_forest_rfe_predictions_threshold <- ifelse(random_forest_rfe_predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
random_forest_rfe_metrics <- get_metrics(random_forest_rfe_predictions_threshold, test$has_card, "Random Forest (RFE)")
metrics_all <- bind_rows(metrics_all, random_forest_rfe_metrics)
random_forest_rfe_metrics
}
```

```{r}
metrics_all
```

```{r}
ggplot(metrics_all, aes(x = model, y = f1)) + geom_point() + geom_line(aes(group = 1)) + ylim(0.5,1)

```


```{r}
# Next, create a plot using ggplot() and specify the dataframe as the first argument
ggplot(data = metrics_all, aes(x = model)) +

# Use geom_line() to create a line plot, and map the F1 metric to the y-axis with aes()
geom_line(aes(y = f1))

# Finally, use labs() to label the x- and y-axes and give the plot a title
labs(x = "Model", y = "F1 value", title = "Model performance (F1)")
```


```{r}
# Next, create a plot using ggplot() and specify the dataframe as the first argument
ggplot(data = metrics_all, aes(x = model)) +

# Use geom_line() to create a line plot, and map the different metrics to the y-axis and the color aesthetic with aes()
geom_line(aes(y = accuracy, color = "Accuracy")) +
geom_line(aes(y = kappa, color = "Kappa")) +
geom_line(aes(y = matthews, color = "Matthews")) +
geom_line(aes(y = precision, color = "Precision")) +
geom_line(aes(y = recall, color = "Recall")) +
geom_line(aes(y = f1, color = "F1"))

# Use scale_color_manual() to specify the colors for each metric
scale_color_manual(values = c("Accuracy" = "blue", "Kappa" = "red", "Matthews" = "green", "Precision" = "purple", "Recall" = "orange", "F1" = "pink"))

# Finally, use labs() to label the x- and y-axes and give the plot a title
labs(x = "Model", y = "Metric value", title = "Model performance")
```


```{r}
#comparison <- compare(regression_baseline_explainer, regression_all_explainer, decision_tree_explainer, random_forest_explainer)

vip_baseline <- variable_importance(regression_baseline_explainer, n_sample = -1, loss_function = loss_root_mean_square) 
vip_regression_all  <- variable_importance(regression_all_explainer, n_sample = -1, loss_function = loss_root_mean_square)
vip_decision_tree <- variable_importance(decision_tree_explainer, n_sample = -1, loss_function = loss_root_mean_square)
vip_random_forest <- variable_importance(random_forest_explainer, n_sample = -1, loss_function = loss_root_mean_square)

plot(vip_baseline, vip_regression_all, vip_decision_tree, vip_random_forest, max_vars = 10)
```


```{r}
fehler
```




## Hyperparameteroptimierung

```{r}
if (FALSE) {
# Set the seed for reproducibility
set.seed(27)

train$has_card <- as.numeric(train$has_card)
test$has_card <- as.numeric(test$has_card)

# Convert the data to a matrix
mat <- as.matrix(train %>% select(has_card, importance_values$variable[1:7]))

# Split the data into training and testing sets
train_ind <- sample(1:nrow(mat), nrow(mat) * 0.8)
train_mat <- mat[train_ind, ]
test_mat <- mat[-train_ind, ]

# Split the labels and predictors
train_labels <- train_mat[, 1]
train_preds <- train_mat[, -1]
test_labels <- test_mat[, 1]
test_preds <- test_mat[, -1]

train_labels <- as.factor(train_labels)
test_labels <- as.factor(test_labels)

# Define the hyperparameter grid
param_grid <- expand.grid(nrounds = c(1000, 2000, 5000),
                         eta = c(0.1, 0.2, 0.3),
                         max_depth = c(3, 5, 7, 10),
                         gamma = c(0, 0.1, 0.2, 1),
                         colsample_bytree = c(0.5, 0.8),
                         min_child_weight = c(1, 3, 5),
                         subsample = c(0.5, 0.8, 1))

# Train the model using caret's train() function
xg_boost_hyperparameter <- train(x = train_preds, y = train_labels, method = "xgbTree", trControl = trainControl(method = "cv", number = 10), tuneGrid = param_grid, metric = "F", verbose = FALSE, verbosity = 0)


print(model)

# Make predictions on the test data
xg_boost_hyperparameter_predictions <- predict(xg_boost_hyperparameter, test_preds)

# Threshold the predicted probabilities
threshold <- 0.5
xg_boost_hyperparameter_predictions_threshold <- ifelse(xg_boost_hyperparameter_predictions > threshold, TRUE, FALSE)

# Evaluate the model's performance
xg_boost_hyperparamter_metrics <- get_metrics(xg_boost_hyperparameter_predictions_threshold, test_labels)
metrics_all <- bind_rows(metrics_all, xg_boost_hyperparamter_metrics)
xg_boost_hyperparamter_metrics
}
```


# Übersicht über alle Modelle

```{r}
metrics_all
```


# Fazit

## Mehrwert des Modells in der Praxis

Bei unserem Model handelt es sich um ein Product Affinity Model. Es soll voraussagen, ob eine Person (hier eine Kund:in der Bank) ein bestimmtes Produkt kauft (hier eine Kreditkarte) oder nicht. Ausserdem gibt unser Modell auch an, mit welcher Wahrscheinlichkeit sie diese kauft. Dies könnte von grossem Mehrwert für eine Bank sein, da sie anhand des Modells die Marketing-Strategie optimieren und ihre Ressourcen gezielter einsetzen können.

Es kann Banken helfen, ihre Marketing-Bemühungen besser zu segmentieren, indem es zeigt, wer wahrscheinlich an einer Kreditkarte interessiert ist und wer nicht. Dies kann dazu beitragen, die Conversion-Rate zu verbessern und die Kosten für Marketing-Aktionen zu senken. 

Ein weiterer Vorteil, den ein Product Affinity Model bieten kann, ist, dass es Banken helfen kann, ihre Kundenbeziehungen zu verbessern, indem es ihnen ermöglicht, personalisierte Angebote und Services anzubieten.

Wenn das Modell vorhersagt, wer wahrscheinlich eine Kreditkarte kaufen wird, können Banken ihren Kunden personalisierte Angebote und Services anbieten, die auf ihre individuellen Bedürfnisse und Vorlieben abgestimmt sind. Dies kann dazu beitragen, die Kundenzufriedenheit zu erhöhen und die Kundenbindung zu stärken. Dafür müsste das Modell aber noch erweitert werden.

Ein personalisiertes Angebot könnte beispielsweise eine Kreditkarte sein, die speziell auf die Bedürfnisse und Vorlieben eines Kunden abgestimmt ist, z.B. mit einem hohen Rückzahlungsprozentsatz für bestimmte Kategorien von Einkäufen oder mit Reiseversicherungen und anderen Vorteilen, die für den Kunden besonders wichtig sind.

Indem Banken ihren Kunden personalisierte Angebote und Services anbieten, können sie ihre Beziehungen zu ihnen stärken und ihre Zufriedenheit erhöhen.

